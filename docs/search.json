[
  {
    "objectID": "mgta495hw1.html",
    "href": "mgta495hw1.html",
    "title": "Charitable Contribution Made",
    "section": "",
    "text": "pip install pandas pyreadstat\n\nRequirement already satisfied: pandas in /home/jovyan/.rsm-msba/lib/python3.11/site-packages (2.2.3)\nRequirement already satisfied: pyreadstat in /opt/conda/lib/python3.11/site-packages (1.2.8)\nRequirement already satisfied: numpy&gt;=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\nRequirement already satisfied: pytz&gt;=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\nRequirement already satisfied: six&gt;=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\nimport pandas as pd\n\n# Load the Stata file\nfile_path = \"karlan_list_2007.dta\"\ndf = pd.read_stata(file_path)\n\n# Display basic information\nprint(\"Dataset Info:\")\nprint(df.info())\n\nDataset Info:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\nNone\n# Show first few rows\nprint(\"\\nFirst 5 rows:\")\nprint(df.head())\n\n\nFirst 5 rows:\n   treatment  control    ratio  ratio2  ratio3      size  size25  size50  \\\n0          0        1  Control       0       0   Control       0       0   \n1          0        1  Control       0       0   Control       0       0   \n2          1        0        1       0       0  $100,000       0       0   \n3          1        0        1       0       0  Unstated       0       0   \n4          1        0        1       0       0   $50,000       0       1   \n\n   size100  sizeno  ... redcty  bluecty    pwhite    pblack  page18_39  \\\n0        0       0  ...    0.0      1.0  0.446493  0.527769   0.317591   \n1        0       0  ...    1.0      0.0       NaN       NaN        NaN   \n2        1       0  ...    0.0      1.0  0.935706  0.011948   0.276128   \n3        0       1  ...    1.0      0.0  0.888331  0.010760   0.279412   \n4        0       0  ...    0.0      1.0  0.759014  0.127421   0.442389   \n\n   ave_hh_sz  median_hhincome    powner  psch_atlstba  pop_propurban  \n0       2.10          28517.0  0.499807      0.324528            1.0  \n1        NaN              NaN       NaN           NaN            NaN  \n2       2.48          51175.0  0.721941      0.192668            1.0  \n3       2.65          79269.0  0.920431      0.412142            1.0  \n4       1.85          40908.0  0.416072      0.439965            1.0  \n\n[5 rows x 51 columns]\n# Show summary statistics\nprint(\"\\nSummary statistics:\")\nprint(df.describe(include='all'))\n\n\nSummary statistics:\n           treatment       control    ratio        ratio2        ratio3  \\\ncount   50083.000000  50083.000000    50083  50083.000000  50083.000000   \nunique           NaN           NaN        4           NaN           NaN   \ntop              NaN           NaN  Control           NaN           NaN   \nfreq             NaN           NaN    16687           NaN           NaN   \nmean        0.666813      0.333187      NaN      0.222311      0.222211   \nstd         0.471357      0.471357      NaN      0.415803      0.415736   \nmin         0.000000      0.000000      NaN      0.000000      0.000000   \n25%         0.000000      0.000000      NaN      0.000000      0.000000   \n50%         1.000000      0.000000      NaN      0.000000      0.000000   \n75%         1.000000      1.000000      NaN      0.000000      0.000000   \nmax         1.000000      1.000000      NaN      1.000000      1.000000   \n\n           size        size25        size50       size100        sizeno  ...  \\\ncount     50083  50083.000000  50083.000000  50083.000000  50083.000000  ...   \nunique        5           NaN           NaN           NaN           NaN  ...   \ntop     Control           NaN           NaN           NaN           NaN  ...   \nfreq      16687           NaN           NaN           NaN           NaN  ...   \nmean        NaN      0.166723      0.166623      0.166723      0.166743  ...   \nstd         NaN      0.372732      0.372643      0.372732      0.372750  ...   \nmin         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n25%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n50%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n75%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \nmax         NaN      1.000000      1.000000      1.000000      1.000000  ...   \n\n              redcty       bluecty        pwhite        pblack     page18_39  \\\ncount   49978.000000  49978.000000  48217.000000  48047.000000  48217.000000   \nunique           NaN           NaN           NaN           NaN           NaN   \ntop              NaN           NaN           NaN           NaN           NaN   \nfreq             NaN           NaN           NaN           NaN           NaN   \nmean        0.510245      0.488715      0.819599      0.086710      0.321694   \nstd         0.499900      0.499878      0.168560      0.135868      0.103039   \nmin         0.000000      0.000000      0.009418      0.000000      0.000000   \n25%         0.000000      0.000000      0.755845      0.014729      0.258311   \n50%         1.000000      0.000000      0.872797      0.036554      0.305534   \n75%         1.000000      1.000000      0.938827      0.090882      0.369132   \nmax         1.000000      1.000000      1.000000      0.989622      0.997544   \n\n           ave_hh_sz  median_hhincome        powner  psch_atlstba  \\\ncount   48221.000000     48209.000000  48214.000000  48215.000000   \nunique           NaN              NaN           NaN           NaN   \ntop              NaN              NaN           NaN           NaN   \nfreq             NaN              NaN           NaN           NaN   \nmean        2.429012     54815.700533      0.669418      0.391661   \nstd         0.378105     22027.316665      0.193405      0.186599   \nmin         0.000000      5000.000000      0.000000      0.000000   \n25%         2.210000     39181.000000      0.560222      0.235647   \n50%         2.440000     50673.000000      0.712296      0.373744   \n75%         2.660000     66005.000000      0.816798      0.530036   \nmax         5.270000    200001.000000      1.000000      1.000000   \n\n        pop_propurban  \ncount    48217.000000  \nunique            NaN  \ntop               NaN  \nfreq              NaN  \nmean         0.871968  \nstd          0.258633  \nmin          0.000000  \n25%          0.884929  \n50%          1.000000  \n75%          1.000000  \nmax          1.000000  \n\n[11 rows x 51 columns]\nfrom scipy.stats import ttest_ind\n\n%pip install statsmodels\nimport statsmodels.formula.api as smf\nimport statsmodels.api as sm\n\nRequirement already satisfied: statsmodels in /home/jovyan/.rsm-msba/lib/python3.11/site-packages (0.14.4)\nRequirement already satisfied: numpy&lt;3,&gt;=1.22.3 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (1.26.4)\nRequirement already satisfied: scipy!=1.9.2,&gt;=1.8 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (1.12.0)\nRequirement already satisfied: pandas!=2.1.0,&gt;=1.4 in /home/jovyan/.rsm-msba/lib/python3.11/site-packages (from statsmodels) (2.2.3)\nRequirement already satisfied: patsy&gt;=0.5.6 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (0.5.6)\nRequirement already satisfied: packaging&gt;=21.3 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (24.1)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (2.9.0)\nRequirement already satisfied: pytz&gt;=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (2024.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from patsy&gt;=0.5.6-&gt;statsmodels) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n# Add an intercept column to the DataFrame\ndf['intercept'] = 1\n\n# Ensure consistent data for both t-test and regression\nconsistent_data = df[['mrm2', 'treatment', 'control', 'intercept']].dropna()\n\n# Perform a t-test\ntreatment_group = consistent_data[consistent_data['treatment'] == 1]['mrm2']\ncontrol_group = consistent_data[consistent_data['control'] == 1]['mrm2']\nt_stat, p_value_ttest = ttest_ind(treatment_group, control_group, equal_var=False)\n\nprint(f\"T-test results:\")\nprint(f\"T-statistic: {t_stat:.4f}, P-value: {p_value_ttest:.4f}\")\n\n# Perform a linear regression\nmodel = sm.OLS(consistent_data['mrm2'], consistent_data[['intercept', 'treatment']])\nresults = model.fit()\n\nprint(\"\\nLinear Regression results:\")\nprint(results.summary())\n\n# Confirm the p-value matches\np_value_regression = results.pvalues['treatment']\nprint(f\"\\nP-value from regression: {p_value_regression:.4f}\")\nassert abs(p_value_ttest - p_value_regression) &lt; 1e-3, \"P-values do not match!\"\n\nT-test results:\nT-statistic: 0.1195, P-value: 0.9049\n\nLinear Regression results:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   mrm2   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01428\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.905\nTime:                        22:50:37   Log-Likelihood:            -1.9585e+05\nNo. Observations:               50082   AIC:                         3.917e+05\nDf Residuals:                   50080   BIC:                         3.917e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept     12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\nOmnibus:                     8031.352   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\nSkew:                           1.163   Prob(JB):                         0.00\nKurtosis:                       3.751   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nP-value from regression: 0.9049\nimport matplotlib.pyplot as plt\n\n# Calculate the proportion of people who donated in each group\ntreatment_proportion = df[df['treatment'] == 1]['gave'].mean()\ncontrol_proportion = df[df['control'] == 1]['gave'].mean()\n\n# Create the barplot\nplt.bar(['Treatment', 'Control'], [treatment_proportion, control_proportion], color=['blue', 'orange'])\nplt.ylabel('Proportion of People Who Donated')\nplt.title('Proportion of Donors by Group')\n# Display the proportions\nprint(f\"Proportion of people who donated in the Treatment group: {treatment_proportion:.2%}\")\nprint(f\"Proportion of people who donated in the Control group: {control_proportion:.2%}\")\n\nplt.show()\n\nProportion of people who donated in the Treatment group: 2.20%\nProportion of people who donated in the Control group: 1.79%\n# Extract the binary outcome for treatment and control groups\ntreatment_gave = df[df['treatment'] == 1]['gave'].dropna()\ncontrol_gave = df[df['control'] == 1]['gave'].dropna()\n\n# Perform a t-test\nt_stat_gave, p_value_gave = ttest_ind(treatment_gave, control_gave, equal_var=False)\n\nprint(f\"T-test results for charitable donation (gave):\")\nprint(f\"T-statistic: {t_stat_gave:.4f}, P-value: {p_value_gave:.4f}\")\n\nT-test results for charitable donation (gave):\nT-statistic: 3.2095, P-value: 0.0013\n# Perform a bivariate linear regression\nbivariate_model = sm.OLS(df['gave'], df[['intercept', 'treatment']])\nbivariate_results = bivariate_model.fit()\n\nprint(\"\\nBivariate Linear Regression results:\")\nprint(bivariate_results.summary())\n\n# Extract the p-value for the treatment variable\nbivariate_p_value = bivariate_results.pvalues['treatment']\nprint(f\"\\nP-value for treatment in bivariate regression: {bivariate_p_value:.4f}\")\n\n\nBivariate Linear Regression results:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):            0.00193\nTime:                        22:50:38   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nP-value for treatment in bivariate regression: 0.0019\n# Perform a probit regression\nprobit_model = smf.probit('gave ~ treatment', data=df)\nprobit_results = probit_model.fit()\n\n# Display the summary of the probit regression\nprint(\"\\nProbit Regression results:\")\nprint(probit_results.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\nProbit Regression results:\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        22:50:39   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n=============================================================================="
  },
  {
    "objectID": "mgta495hw1.html#simulation-experiment",
    "href": "mgta495hw1.html#simulation-experiment",
    "title": "Charitable Contribution Made",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\n# Parameters\np_no_match = 0.018  # Probability of donation without match\np_with_match = 0.022  # Probability of donation with match\nsample_sizes = [10, 50, 100, 500, 1000, 5000, 10000]  # Different sample sizes\nnum_simulations = 1000  # Number of simulations for CLT\n\n# Law of Large Numbers (LLN)\nmeans_no_match = []\nmeans_with_match = []\n\nfor size in sample_sizes:\n    sample_no_match = np.random.binomial(1, p_no_match, size)\n    sample_with_match = np.random.binomial(1, p_with_match, size)\n    means_no_match.append(np.mean(sample_no_match))\n    means_with_match.append(np.mean(sample_with_match))\n\n# Plot LLN\nplt.figure(figsize=(12, 6))\nplt.plot(sample_sizes, means_no_match, label=\"No Match (p=0.018)\", marker='o')\nplt.plot(sample_sizes, means_with_match, label=\"With Match (p=0.022)\", marker='o')\nplt.axhline(y=p_no_match, color='blue', linestyle='--', label=\"True Mean (No Match)\")\nplt.axhline(y=p_with_match, color='orange', linestyle='--', label=\"True Mean (With Match)\")\nplt.xlabel(\"Sample Size\")\nplt.ylabel(\"Sample Mean\")\nplt.title(\"Law of Large Numbers\")\nplt.legend()\nplt.grid()\nplt.show()\n\n# Central Limit Theorem (CLT)\nsample_means_no_match = []\nsample_means_with_match = []\n\nfor _ in range(num_simulations):\n    sample_no_match = np.random.binomial(1, p_no_match, 1000)  # Fixed sample size\n    sample_with_match = np.random.binomial(1, p_with_match, 1000)\n    sample_means_no_match.append(np.mean(sample_no_match))\n    sample_means_with_match.append(np.mean(sample_with_match))\n\n# Plot CLT\nplt.figure(figsize=(12, 6))\nplt.hist(sample_means_no_match, bins=30, alpha=0.7, label=\"No Match (p=0.018)\", color='blue', edgecolor='black')\nplt.hist(sample_means_with_match, bins=30, alpha=0.7, label=\"With Match (p=0.022)\", color='orange', edgecolor='black')\nplt.axvline(x=p_no_match, color='blue', linestyle='--', label=\"True Mean (No Match)\")\nplt.axvline(x=p_with_match, color='orange', linestyle='--', label=\"True Mean (With Match)\")\nplt.xlabel(\"Sample Mean\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Central Limit Theorem\")\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLaw of Large Numbers\n\nimport numpy as np\n\n# Filter the control group\ncontrol_amounts = df[df['control'] == 1]['amount']\n\n# Simulate 100,000 draws from the control distribution\nsimulated_draws = np.random.choice(control_amounts, size=100000, replace=True)\n\n# Display summary statistics of the simulated draws\nprint(f\"Simulated Draws Summary:\")\nprint(f\"Mean: {np.mean(simulated_draws):.4f}\")\nprint(f\"Standard Deviation: {np.std(simulated_draws):.4f}\")\nprint(f\"Min: {np.min(simulated_draws):.4f}\")\nprint(f\"Max: {np.max(simulated_draws):.4f}\")\n\nSimulated Draws Summary:\nMean: 0.8120\nStandard Deviation: 8.2383\nMin: 0.0000\nMax: 300.0000\n\n\n\n# Filter the treatment group\ntreatment_amounts = df[df['treatment'] == 1]['amount']\n\n# Simulate 10,000 draws from the treatment distribution\nsimulated_treatment_draws = np.random.choice(treatment_amounts, size=10000, replace=True)\n\n# Display summary statistics of the simulated treatment draws\nprint(f\"Simulated Treatment Draws Summary:\")\nprint(f\"Mean: {np.mean(simulated_treatment_draws):.4f}\")\nprint(f\"Standard Deviation: {np.std(simulated_treatment_draws):.4f}\")\nprint(f\"Min: {np.min(simulated_treatment_draws):.4f}\")\nprint(f\"Max: {np.max(simulated_treatment_draws):.4f}\")\n\nSimulated Treatment Draws Summary:\nMean: 0.8502\nStandard Deviation: 8.7401\nMin: 0.0000\nMax: 400.0000\n\n\n\n# Simulate 100,000 draws from the control distribution\nsimulated_control_draws = np.random.choice(control_amounts, size=100000, replace=True)\n\n# Simulate 10,000 draws from the treatment distribution\nsimulated_treatment_draws = np.random.choice(treatment_amounts, size=10000, replace=True)\n\n# Calculate a vector of 10,000 differences\ndifferences = simulated_treatment_draws - simulated_control_draws[:10000]\n\n# Calculate the cumulative average of the differences\ncumulative_avg = np.cumsum(differences) / np.arange(1, len(differences) + 1)\n\n# Plot the cumulative average\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_avg, label=\"Cumulative Average of Differences\")\nplt.axhline(0, color='red', linestyle='--', label=\"Zero Line\")\nplt.xlabel(\"Number of Differences\")\nplt.ylabel(\"Cumulative Average\")\nplt.title(\"Cumulative Average of Differences Between Treatment and Control\")\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import norm\n\n# Add a distribution curve to the plot\n# Fit a normal distribution to the differences\nmean_diff = np.mean(differences)\nstd_diff = np.std(differences)\n\n# Generate x values for the curve\nx = np.linspace(min(differences), max(differences), 1000)\ny = norm.pdf(x, mean_diff, std_diff)\n\n# Plot the distribution curve\nplt.figure(figsize=(10, 6))\nplt.plot(x, y, label=\"Normal Distribution Curve\", color='purple')\nplt.hist(differences, bins=50, density=True, alpha=0.6, color='gray', edgecolor='black')\nplt.axvline(0, color='red', linestyle='--', label=\"Zero Line\")\nplt.xlabel(\"Differences\")\nplt.ylabel(\"Density\")\nplt.title(\"Distribution of Differences with Fitted Curve\")\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\n\n# Set the sample size and number of repetitions\nsample_size = 500\nnum_repetitions = 1000\n\n# Initialize a list to store the average differences\naverage_differences = []\n\n# Perform the simulation\nfor _ in range(num_repetitions):\n    # Take random draws from the control and treatment distributions\n    control_sample = np.random.choice(control_amounts, size=sample_size, replace=True)\n    treatment_sample = np.random.choice(treatment_amounts, size=sample_size, replace=True)\n    \n    # Calculate the average difference and store it\n    avg_diff = np.mean(treatment_sample) - np.mean(control_sample)\n    average_differences.append(avg_diff)\n\n# Plot the histogram of the average differences\nplt.figure(figsize=(10, 6))\nplt.hist(average_differences, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\nplt.axvline(np.mean(average_differences), color='red', linestyle='--', label=f'Mean: {np.mean(average_differences):.4f}')\nplt.xlabel('Average Difference')\nplt.ylabel('Frequency')\nplt.title('Histogram of Average Differences for a Sample Size of 500')\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Set the sample size and number of repetitions\nsample_size = 50\nnum_repetitions = 1000\n\n# Initialize a list to store the average differences\naverage_differences = []\n\n# Perform the simulation\nfor _ in range(num_repetitions):\n    # Take random draws from the control and treatment distributions\n    control_sample = np.random.choice(control_amounts, size=sample_size, replace=True)\n    treatment_sample = np.random.choice(treatment_amounts, size=sample_size, replace=True)\n    \n    # Calculate the average difference and store it\n    avg_diff = np.mean(treatment_sample) - np.mean(control_sample)\n    average_differences.append(avg_diff)\n\n# Plot the histogram of the average differences\nplt.figure(figsize=(10, 6))\nplt.hist(average_differences, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\nplt.axvline(np.mean(average_differences), color='red', linestyle='--', label=f'Mean: {np.mean(average_differences):.4f}')\nplt.xlabel('Average Difference')\nplt.ylabel('Frequency')\nplt.title('Histogram of Average Differences for a Sample Size of 50')\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Set the sample size and number of repetitions\nsample_size = 1000\nnum_repetitions = 1000\n\n# Initialize a list to store the average differences\naverage_differences = []\n\n# Perform the simulation\nfor _ in range(num_repetitions):\n    # Take random draws from the control and treatment distributions\n    control_sample = np.random.choice(control_amounts, size=sample_size, replace=True)\n    treatment_sample = np.random.choice(treatment_amounts, size=sample_size, replace=True)\n    \n    # Calculate the average difference and store it\n    avg_diff = np.mean(treatment_sample) - np.mean(control_sample)\n    average_differences.append(avg_diff)\n\n# Plot the histogram of the average differences\nplt.figure(figsize=(10, 6))\nplt.hist(average_differences, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\nplt.axvline(np.mean(average_differences), color='red', linestyle='--', label=f'Mean: {np.mean(average_differences):.4f}')\nplt.xlabel('Average Difference')\nplt.ylabel('Frequency')\nplt.title('Histogram of Average Differences for a Sample Size of 1000')\nplt.legend()\nplt.grid()\nplt.show()"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Homework",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2025\n\n\nYour Name\n\n\n\n\n\n\n\n\n\n\n\n\nK-Means Analysis\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2025\n\n\nAnjana Khabir\n\n\n\n\n\n\n\n\n\n\n\n\nKey Drivers Analysis\n\n\n\n\n\n\n\n\n\n\n\nJun 11, 2025\n\n\nAnjana Khabir\n\n\n\n\n\n\n\n\n\n\n\n\nMultinomial Logit Model\n\n\n\n\n\n\n\n\n\n\n\nMay 27, 2025\n\n\nAnjana Khabir\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\n\n\n\n\n\nMay 7, 2025\n\n\nAnjana Khabir\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/homework1/index.html",
    "href": "projects/homework1/index.html",
    "title": "Homework 1",
    "section": "",
    "text": "Heading!\nSome text."
  },
  {
    "objectID": "projects/homework1/hw2_questions.html",
    "href": "projects/homework1/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nimport pandas as pd\nimport seaborn as sns\n\n# Load the Blueprinty data\ndata = pd.read_csv('/home/jovyan/Desktop/marketingwebsite/blueprinty.csv')\n\n# Display the first few rows of the dataset\ndata.head()\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(8, 6))\npalette = {0: \"#2ca02c\", 1: \"#d62728\"}  \nsns.set(style=\"darkgrid\") \nsns.histplot(data=data, x=\"patents\", hue=\"iscustomer\", bins=20, multiple=\"dodge\", palette=palette)\nplt.title(\"Number of Patents by Customer Status\", fontsize=14)\nplt.xlabel(\"Number of Patents\", fontsize=12)\nplt.ylabel(\"Number of Firms\", fontsize=12)\nplt.legend(title=\"Is Customer\", labels=[\"Non-Customer\", \"Customer\"], fontsize=10)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Filter data into customers and non-customers\ncustomers = data[data['iscustomer'] == 1]\nnon_customers = data[data['iscustomer'] == 0]\n\n# Calculate and print means\nmean_customers = customers['patents'].mean()\nmean_non_customers = non_customers['patents'].mean()\nprint(f\"Mean number of patents for customers: {mean_customers}\")\nprint(f\"Mean number of patents for non-customers: {mean_non_customers}\")\n\nMean number of patents for customers: 4.133056133056133\nMean number of patents for non-customers: 3.4730127576054954"
  },
  {
    "objectID": "projects/homework1/hw2_questions.html#blueprinty-case-study",
    "href": "projects/homework1/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\n\nimport pandas as pd\nimport seaborn as sns\n\n# Load the Blueprinty data\ndata = pd.read_csv('/home/jovyan/Desktop/marketingwebsite/blueprinty.csv')\n\n# Display the first few rows of the dataset\ndata.head()\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(8, 6))\npalette = {0: \"#2ca02c\", 1: \"#d62728\"}  \nsns.set(style=\"darkgrid\") \nsns.histplot(data=data, x=\"patents\", hue=\"iscustomer\", bins=20, multiple=\"dodge\", palette=palette)\nplt.title(\"Number of Patents by Customer Status\", fontsize=14)\nplt.xlabel(\"Number of Patents\", fontsize=12)\nplt.ylabel(\"Number of Firms\", fontsize=12)\nplt.legend(title=\"Is Customer\", labels=[\"Non-Customer\", \"Customer\"], fontsize=10)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Filter data into customers and non-customers\ncustomers = data[data['iscustomer'] == 1]\nnon_customers = data[data['iscustomer'] == 0]\n\n# Calculate and print means\nmean_customers = customers['patents'].mean()\nmean_non_customers = non_customers['patents'].mean()\nprint(f\"Mean number of patents for customers: {mean_customers}\")\nprint(f\"Mean number of patents for non-customers: {mean_non_customers}\")\n\nMean number of patents for customers: 4.133056133056133\nMean number of patents for non-customers: 3.4730127576054954"
  },
  {
    "objectID": "projects/homework1/hw2_questions.html#observations",
    "href": "projects/homework1/hw2_questions.html#observations",
    "title": "Poisson Regression Examples",
    "section": "Observations:",
    "text": "Observations:\nCompanies that use Blueprinty typically hold a higher average number of patents (around 4.13) compared to those that don’t (approximately 3.47). The histogram reveals that customer firms are more frequently found among those with greater patent counts, hinting at a possible positive link between Blueprinty usage and patent performance. Nevertheless, this trend could also be shaped by additional variables like geographic location or the age of the firm, which warrant further investigation.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\npalette = {0: \"#2ca02c\", 1: \"#d62728\"}\nplt.figure(figsize=(8, 6))\nsns.countplot(data=data, x=\"region\", hue=\"iscustomer\", palette=palette)\nplt.title(\"Region Distribution by Customer Status\")\nplt.xlabel(\"Region\")\nplt.ylabel(\"Number of Firms\")\nplt.legend(title=\"Is Customer\", labels=[\"Non-Customer\", \"Customer\"])\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Compare regions by customer status\nregion_counts_customers = customers['region'].value_counts(normalize=True)\nregion_counts_non_customers = non_customers['region'].value_counts(normalize=True)\n\nprint(\"Region distribution for customers:\")\nprint(region_counts_customers)\nprint(\"\\nRegion distribution for non-customers:\")\nprint(region_counts_non_customers)\n\n# Compare ages by customer status\nmean_age_customers = customers['age'].mean()\nmean_age_non_customers = non_customers['age'].mean()\n\nprint(f\"\\nMean age for customers: {mean_age_customers}\")\nprint(f\"Mean age for non-customers: {mean_age_non_customers}\")\n\nRegion distribution for customers:\nregion\nNortheast    0.681913\nSouthwest    0.108108\nMidwest      0.076923\nSouth        0.072765\nNorthwest    0.060291\nName: proportion, dtype: float64\n\nRegion distribution for non-customers:\nregion\nNortheast    0.267910\nSouthwest    0.240432\nMidwest      0.183513\nNorthwest    0.155054\nSouth        0.153091\nName: proportion, dtype: float64\n\nMean age for customers: 26.9002079002079\nMean age for non-customers: 26.101570166830225\n\n\nThe geographic distribution of firms differs between Blueprinty customers and non-customers, with certain regions—such as the Northeast—showing a greater proportion of customer firms. This indicates that regional factors could potentially confound the observed relationship between software adoption and patent performance.\nIn terms of firm age, customers tend to be slightly older on average (approximately 26.9 years) compared to non-customers (about 26.1 years), though the difference is relatively small. Nonetheless, accounting for firm age remains important to ensure the analysis yields unbiased insights.\n\nEstimation of Simple Poisson Model\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\n# Define the Poisson likelihood function\nimport numpy as np\n\ndef poisson_likelihood(lambda_, Y):\n   \"\"\"\n   Compute the Poisson likelihood for given lambda and observed Y.\n   \"\"\"\n   likelihood = np.exp(-lambda_) * (lambda_ ** Y) / np.math.factorial(Y)\n   return likelihood\n\n# Example usage\nY_observed = 5  # Example observed number of patents\nlambda_example = 3.0  # Example lambda value\nlikelihood_value = poisson_likelihood(lambda_example, Y_observed)\nprint(f\"Poisson likelihood for Y={Y_observed} and lambda={lambda_example}: {likelihood_value}\")\n\nPoisson likelihood for Y=5 and lambda=3.0: 0.10081881344492448\n\n\n/tmp/ipykernel_4152/637518867.py:8: DeprecationWarning:\n\n`np.math` is a deprecated alias for the standard library `math` module (Deprecated Numpy 1.25). Replace usages of `np.math` with `math`\n\n\n\n\ndef poisson_loglikelihood(lambda_, Y):\n   \"\"\"\n   Compute the Poisson log-likelihood for given lambda and observed Y.\n   \"\"\"\n   from scipy.special import factorial\n   log_likelihood = np.sum(Y * np.log(lambda_) - lambda_ - np.log(factorial(Y)))\n   return log_likelihood\n\n\n# Define a range of lambda values\nlambda_values = np.linspace(0.1, 10, 100)\n\n# Convert Y_sample to a NumPy array\nY_sample = np.array([5, 3, 4, 6, 2])  # Example observed data\n\n# Compute the log-likelihood for each lambda\nlog_likelihoods = [poisson_loglikelihood(l, Y_sample) for l in lambda_values]\n\n# Plot the log-likelihood\nplt.plot(lambda_values, log_likelihoods, label='Log-Likelihood')\nplt.xlabel('Lambda')\nplt.ylabel('Log-Likelihood')\nplt.title('Log-Likelihood vs Lambda')\nplt.axvline(x=np.mean(Y_sample), color='red', linestyle='--', label='MLE (Mean of Y)')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Derive the first derivative of the log-likelihood function\n# Log-likelihood: l(lambda) = Y * log(lambda) - lambda - log(Y!)\n# First derivative: dl/dlambda = Y / lambda - 1\n\n# Solve for lambda when dl/dlambda = 0\n# Y / lambda - 1 = 0 =&gt; lambda = Y\n\n# For a sample of observations, the MLE for lambda is the sample mean (Ybar)\ndef compute_lambda_mle(Y):\n   \"\"\"\n   Compute the MLE for lambda (mean of Y).\n   \"\"\"\n   return np.mean(Y)\n\n# Example usage\nY_sample = [5, 3, 4, 6, 2]  # Example observed data\nlambda_mle = compute_lambda_mle(Y_sample)\nprint(f\"MLE for lambda (mean of Y): {lambda_mle}\")\n\nMLE for lambda (mean of Y): 4.0\n\n\n\nfrom scipy.optimize import minimize\n\n# Define the negative log-likelihood function for optimization\ndef negative_log_likelihood(lambda_, Y):\n   return -poisson_loglikelihood(lambda_, Y)\n\n# Example observed data\nY_sample = np.array([5, 3, 4, 6, 2])\n\n# Initial guess for lambda\ninitial_guess = np.mean(Y_sample)\n\n# Perform optimization to find the MLE\nresult = minimize(negative_log_likelihood, x0=initial_guess, args=(Y_sample,), bounds=[(0.01, None)])\n\n# Extract the MLE for lambda\nlambda_mle = result.x[0]\nprint(f\"MLE for lambda: {lambda_mle}\")\n\nMLE for lambda: 4.0\n\n\n\n\nEstimation of Poisson Regression Model\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty."
  },
  {
    "objectID": "projects/homework1/hw2_questions.html#validate-the-results-above-using-statsmodels.glm-from-python",
    "href": "projects/homework1/hw2_questions.html#validate-the-results-above-using-statsmodels.glm-from-python",
    "title": "Poisson Regression Examples",
    "section": "Validate the results above using statsmodels.GLM() from Python",
    "text": "Validate the results above using statsmodels.GLM() from Python\n\nimport statsmodels.api as sm\n\n# Drop 'intercept' column and ensure all data is float\nX_glm = X.drop(columns='intercept', errors='ignore').astype(float)\n\n# Add constant for intercept term\nX_glm = sm.add_constant(X_glm)\n\n# Fit GLM model\nglm_model = sm.GLM(Y, X_glm, family=sm.families.Poisson())\nglm_results = glm_model.fit()\n\n# Display summary\nglm_results.summary()\n\n# Conduct coefficient summary and create a table\ncoefficient_summary = glm_results.summary2().tables[1][[\"Coef.\", \"Std.Err.\"]]\n\n# Display table\ncoefficient_summary\n\n\n\n\n\n\n\n\nCoef.\nStd.Err.\n\n\n\n\nconst\n-0.508920\n0.183179\n\n\nage\n0.148619\n0.013869\n\n\nage_squared\n-0.002970\n0.000258\n\n\nNortheast\n0.029170\n0.043625\n\n\nNorthwest\n-0.017575\n0.053781\n\n\nSouth\n0.056561\n0.052662\n\n\nSouthwest\n0.050576\n0.047198\n\n\niscustomer\n0.207591\n0.030895"
  },
  {
    "objectID": "projects/homework1/hw2_questions.html#interpretations",
    "href": "projects/homework1/hw2_questions.html#interpretations",
    "title": "Poisson Regression Examples",
    "section": "Interpretations:",
    "text": "Interpretations:\n\nOlder firms tend to have higher patent counts, indicating a strong positive relationship between age and patenting activity.\nThe negative and significant coefficient on Age² suggests that the positive effect of age weakens over time—patent growth slows as firms mature.\nFirms using Blueprinty are predicted to have 23% more patents than similar non-users, based on a significant coefficient of 0.2076 (p &lt; 0.001).\nDifferences across regions (e.g., Northeast, Northwest) are not statistically significant, suggesting geography has little influence on patent outcomes once other factors are controlled.\nThe effect of Blueprinty’s software is further assessed using counterfactual prediction to isolate its impact."
  },
  {
    "objectID": "projects/homework1/hw2_questions.html#the-effect-of-blueprintys-software-is-further-assessed-using-counterfactual-prediction-to-isolate-its-impact.",
    "href": "projects/homework1/hw2_questions.html#the-effect-of-blueprintys-software-is-further-assessed-using-counterfactual-prediction-to-isolate-its-impact.",
    "title": "Poisson Regression Examples",
    "section": "The effect of Blueprinty’s software is further assessed using counterfactual prediction to isolate its impact.",
    "text": "The effect of Blueprinty’s software is further assessed using counterfactual prediction to isolate its impact.\nWe perform a counterfactual simulation by constructing two hypothetical scenarios:\nX_0: All firms are assigned as non-customers (iscustomer = 0)\nX_1: All firms are assigned as customers (iscustomer = 1)\nUsing the fitted model, we predict the expected number of patents for each firm under both scenarios. The difference in predicted outcomes gives us an estimate of the average effect of using Blueprinty’s software.\n\n# Create counterfactual datasets:\n# X_0: simulate all firms as non-customers\n# X_1: simulate all firms as customers\nX_0 = X_glm.copy()\nX_1 = X_glm.copy()\n\nX_0[\"iscustomer\"] = 0\nX_1[\"iscustomer\"] = 1\n\n# Predict patent counts under both scenarios\ny_pred_0 = glm_results.predict(X_0)\ny_pred_1 = glm_results.predict(X_1)\n\nprint(y_pred_0)\nprint(y_pred_1)\n\n# Calculate the average treatment effect\naverage_effect = np.mean(y_pred_1 - y_pred_0)\n\naverage_effect\n\n0       3.266275\n1       2.553993\n2       3.746253\n3       3.968549\n4       2.648513\n          ...   \n1495    3.501061\n1496    3.982032\n1497    3.352547\n1498    3.894004\n1499    2.283503\nLength: 1500, dtype: float64\n0       4.019836\n1       3.143223\n2       4.610549\n3       4.884131\n4       3.259550\n          ...   \n1495    4.308788\n1496    4.900724\n1497    4.126012\n1498    4.792387\n1499    2.810328\nLength: 1500, dtype: float64\n\n\n0.7927680710452553\n\n\nThe average predicted difference in patent counts between firms that use Blueprinty and those that do not is 0.793. This suggests that, after accounting for firm age and regional factors, Blueprinty customers are expected to file roughly 0.793 more patents over a five-year period than comparable non-customers."
  },
  {
    "objectID": "projects/homework1/hw2_questions.html#airbnb-case-study",
    "href": "projects/homework1/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\n# Load the Blueprinty data\nairbnb = pd.read_csv('/home/jovyan/Desktop/marketingwebsite/airbnb.csv')\n\n# Display the first few rows of the dataset\nairbnb.head()\n\n\n\n\n\n\n\n\nUnnamed: 0\nid\ndays\nlast_scraped\nhost_since\nroom_type\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\ninstant_bookable\n\n\n\n\n0\n1\n2515\n3130\n4/2/2017\n9/6/2008\nPrivate room\n1.0\n1.0\n59\n150\n9.0\n9.0\n9.0\nf\n\n\n1\n2\n2595\n3127\n4/2/2017\n9/9/2008\nEntire home/apt\n1.0\n0.0\n230\n20\n9.0\n10.0\n9.0\nf\n\n\n2\n3\n3647\n3050\n4/2/2017\n11/25/2008\nPrivate room\n1.0\n1.0\n150\n0\nNaN\nNaN\nNaN\nf\n\n\n3\n4\n3831\n3038\n4/2/2017\n12/7/2008\nEntire home/apt\n1.0\n1.0\n89\n116\n9.0\n9.0\n9.0\nf\n\n\n4\n5\n4611\n3012\n4/2/2017\n1/2/2009\nPrivate room\nNaN\n1.0\n39\n93\n9.0\n8.0\n9.0\nt\n\n\n\n\n\n\n\n\nprint(airbnb.shape)\nprint(airbnb.info())\n\n(40628, 14)\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 40628 entries, 0 to 40627\nData columns (total 14 columns):\n #   Column                     Non-Null Count  Dtype  \n---  ------                     --------------  -----  \n 0   Unnamed: 0                 40628 non-null  int64  \n 1   id                         40628 non-null  int64  \n 2   days                       40628 non-null  int64  \n 3   last_scraped               40628 non-null  object \n 4   host_since                 40593 non-null  object \n 5   room_type                  40628 non-null  object \n 6   bathrooms                  40468 non-null  float64\n 7   bedrooms                   40552 non-null  float64\n 8   price                      40628 non-null  int64  \n 9   number_of_reviews          40628 non-null  int64  \n 10  review_scores_cleanliness  30433 non-null  float64\n 11  review_scores_location     30374 non-null  float64\n 12  review_scores_value        30372 non-null  float64\n 13  instant_bookable           40628 non-null  object \ndtypes: float64(5), int64(5), object(4)\nmemory usage: 4.3+ MB\nNone\n\n\n\n# Show the number of missing values in each column\nmissing_values = airbnb.isnull().sum()\nprint(\"Number of missing values in each column:\")\nprint(missing_values)\n\nNumber of missing values in each column:\nUnnamed: 0                       0\nid                               0\ndays                             0\nlast_scraped                     0\nhost_since                      35\nroom_type                        0\nbathrooms                      160\nbedrooms                        76\nprice                            0\nnumber_of_reviews                0\nreview_scores_cleanliness    10195\nreview_scores_location       10254\nreview_scores_value          10256\ninstant_bookable                 0\ndtype: int64\n\n\n\nairbnb.dropna(subset=['review_scores_cleanliness', 'review_scores_location', 'review_scores_value'], inplace=True)\n\n\nairbnb.describe(include='object')\n\n\n\n\n\n\n\n\nlast_scraped\nhost_since\nroom_type\ninstant_bookable\n\n\n\n\ncount\n30346\n30325\n30346\n30346\n\n\nunique\n2\n2747\n3\n2\n\n\ntop\n4/2/2017\n12/21/2015\nEntire home/apt\nf\n\n\nfreq\n19260\n56\n15633\n24410\n\n\n\n\n\n\n\n\nairbnb['last_scraped'] = pd.to_datetime(airbnb['last_scraped'])\nairbnb['host_since'] = pd.to_datetime(airbnb['host_since'])\n\nairbnb['days'] = (airbnb['last_scraped'] - airbnb['host_since']).dt.days\n\nCorrelation Matrix for Numerical Variables\n\nnumeric_cols = ['price', 'bathrooms', 'bedrooms', 'number_of_reviews', \n                'review_scores_cleanliness', 'review_scores_location', \n                'review_scores_value', 'days']\nsns.heatmap(airbnb[numeric_cols].corr(), annot=True)\n\n\n\n\n\n\n\n\nPrice Distribution\n\nsns.histplot(airbnb['price'], bins=50)\n\n\n\n\n\n\n\n\nPrice vs. Room Type\n\nsns.boxplot(x='room_type', y='price', data=airbnb)\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Model Using statsmodels.GLM()\n\n# Prepare the design matrix X and response variable Y\nairbnb['room_type_encoded'] = airbnb['room_type'].astype('category').cat.codes\nX_airbnb = airbnb[['bathrooms', 'bedrooms', 'number_of_reviews', \n                   'review_scores_cleanliness', 'review_scores_location', \n                   'review_scores_value', 'days', 'room_type_encoded']]\n\n# Drop rows with NaN or infinite values\nX_airbnb = X_airbnb.replace([np.inf, -np.inf], np.nan).dropna()\nY_airbnb = airbnb.loc[X_airbnb.index, 'price']  # Ensure Y matches filtered X\n\nX_airbnb = sm.add_constant(X_airbnb)  # Add intercept term\n\n# Fit Poisson regression model\npoisson_model = sm.GLM(Y_airbnb, X_airbnb, family=sm.families.Poisson())\npoisson_results = poisson_model.fit()\n\n# Display summary of the model\npoisson_results.summary()\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\nprice\nNo. Observations:\n30140\n\n\nModel:\nGLM\nDf Residuals:\n30131\n\n\nModel Family:\nPoisson\nDf Model:\n8\n\n\nLink Function:\nLog\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-7.9040e+05\n\n\nDate:\nWed, 28 May 2025\nDeviance:\n1.3836e+06\n\n\nTime:\n14:07:04\nPearson chi2:\n7.00e+06\n\n\nNo. Iterations:\n6\nPseudo R-squ. (CS):\n1.000\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n3.4662\n0.007\n471.643\n0.000\n3.452\n3.481\n\n\nbathrooms\n0.3205\n0.001\n317.972\n0.000\n0.319\n0.322\n\n\nbedrooms\n0.1852\n0.001\n302.587\n0.000\n0.184\n0.186\n\n\nnumber_of_reviews\n-0.0001\n1.6e-05\n-9.048\n0.000\n-0.000\n-0.000\n\n\nreview_scores_cleanliness\n0.0122\n0.001\n21.254\n0.000\n0.011\n0.013\n\n\nreview_scores_location\n0.1820\n0.001\n251.122\n0.000\n0.181\n0.183\n\n\nreview_scores_value\n-0.0785\n0.001\n-109.002\n0.000\n-0.080\n-0.077\n\n\ndays\n3.758e-05\n7.59e-07\n49.498\n0.000\n3.61e-05\n3.91e-05\n\n\nroom_type_encoded\n-0.6924\n0.001\n-648.907\n0.000\n-0.694\n-0.690"
  },
  {
    "objectID": "projects/homework1/hw2_questions.html#interpretation",
    "href": "projects/homework1/hw2_questions.html#interpretation",
    "title": "Poisson Regression Examples",
    "section": "Interpretation",
    "text": "Interpretation\nIntercept (3.4662): Represents the baseline log-expected value of the outcome when all other variables are set to zero.\nBathrooms (+0.3205): Listings with more bathrooms are associated with higher expected counts of the outcome. Each additional bathroom increases the expected count on the log scale.\nBedrooms (+0.1852): More bedrooms are linked to higher activity—each additional bedroom raises the expected log count.\nNumber of Reviews (-0.0001): Having more past reviews is slightly negatively associated with the expected count. The effect is small but statistically significant.\nCleanliness Score (+0.0122): Higher cleanliness ratings are associated with modest increases in the expected count of the outcome.\nLocation Score (+0.1820): Better-rated locations show a strong positive association with the expected outcome.\nValue Score (-0.0785): Surprisingly, higher value ratings are linked to lower expected counts. This may suggest that “value” is higher in less competitive or less booked listings.\nDays (+0.00003758): Listings that have been active longer tend to show slightly higher expected counts, reflecting accumulated exposure over time.\nRoom Type (Encoded) (-0.6924): The room type significantly influences outcomes. Encoded types (likely private/shared rooms) are associated with notably lower expected counts compared to the reference category."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "My Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects/homework1/hw1_questions.html",
    "href": "projects/homework1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results.\nIn an effort to rigorously test fundraising strategies, Karlan and List conducted a large-scale natural field experiment involving over 50,000 prior donors to a politically oriented nonprofit organization. The central objective was to investigate whether and how price-like mechanisms—specifically matching grants—affect charitable giving behavior."
  },
  {
    "objectID": "projects/homework1/hw1_questions.html#introduction",
    "href": "projects/homework1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results.\nIn an effort to rigorously test fundraising strategies, Karlan and List conducted a large-scale natural field experiment involving over 50,000 prior donors to a politically oriented nonprofit organization. The central objective was to investigate whether and how price-like mechanisms—specifically matching grants—affect charitable giving behavior."
  },
  {
    "objectID": "projects/homework1/hw1_questions.html#data",
    "href": "projects/homework1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport sys\nprint(sys.version)\n\n3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:25:01) [GCC 12.3.0]\n\n\n\nimport pandas as pd\n\n# Load the Stata file\nfile_path = \"/home/jovyan/Desktop/marketingwebsite/karlan_list_2007.dta\"\ndf = pd.read_stata(file_path)\n\n# Display basic information\nprint(\"Dataset Info:\")\nprint(df.info())\n\nDataset Info:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\nNone\n\n\n\n# Show summary statistics\nprint(\"\\nSummary statistics:\")\nprint(df.describe(include='all'))\n\n\nSummary statistics:\n           treatment       control    ratio        ratio2        ratio3  \\\ncount   50083.000000  50083.000000    50083  50083.000000  50083.000000   \nunique           NaN           NaN        4           NaN           NaN   \ntop              NaN           NaN  Control           NaN           NaN   \nfreq             NaN           NaN    16687           NaN           NaN   \nmean        0.666813      0.333187      NaN      0.222311      0.222211   \nstd         0.471357      0.471357      NaN      0.415803      0.415736   \nmin         0.000000      0.000000      NaN      0.000000      0.000000   \n25%         0.000000      0.000000      NaN      0.000000      0.000000   \n50%         1.000000      0.000000      NaN      0.000000      0.000000   \n75%         1.000000      1.000000      NaN      0.000000      0.000000   \nmax         1.000000      1.000000      NaN      1.000000      1.000000   \n\n           size        size25        size50       size100        sizeno  ...  \\\ncount     50083  50083.000000  50083.000000  50083.000000  50083.000000  ...   \nunique        5           NaN           NaN           NaN           NaN  ...   \ntop     Control           NaN           NaN           NaN           NaN  ...   \nfreq      16687           NaN           NaN           NaN           NaN  ...   \nmean        NaN      0.166723      0.166623      0.166723      0.166743  ...   \nstd         NaN      0.372732      0.372643      0.372732      0.372750  ...   \nmin         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n25%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n50%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n75%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \nmax         NaN      1.000000      1.000000      1.000000      1.000000  ...   \n\n              redcty       bluecty        pwhite        pblack     page18_39  \\\ncount   49978.000000  49978.000000  48217.000000  48047.000000  48217.000000   \nunique           NaN           NaN           NaN           NaN           NaN   \ntop              NaN           NaN           NaN           NaN           NaN   \nfreq             NaN           NaN           NaN           NaN           NaN   \nmean        0.510245      0.488715      0.819599      0.086710      0.321694   \nstd         0.499900      0.499878      0.168560      0.135868      0.103039   \nmin         0.000000      0.000000      0.009418      0.000000      0.000000   \n25%         0.000000      0.000000      0.755845      0.014729      0.258311   \n50%         1.000000      0.000000      0.872797      0.036554      0.305534   \n75%         1.000000      1.000000      0.938827      0.090882      0.369132   \nmax         1.000000      1.000000      1.000000      0.989622      0.997544   \n\n           ave_hh_sz  median_hhincome        powner  psch_atlstba  \\\ncount   48221.000000     48209.000000  48214.000000  48215.000000   \nunique           NaN              NaN           NaN           NaN   \ntop              NaN              NaN           NaN           NaN   \nfreq             NaN              NaN           NaN           NaN   \nmean        2.429012     54815.700533      0.669418      0.391661   \nstd         0.378105     22027.316665      0.193405      0.186599   \nmin         0.000000      5000.000000      0.000000      0.000000   \n25%         2.210000     39181.000000      0.560222      0.235647   \n50%         2.440000     50673.000000      0.712296      0.373744   \n75%         2.660000     66005.000000      0.816798      0.530036   \nmax         5.270000    200001.000000      1.000000      1.000000   \n\n        pop_propurban  \ncount    48217.000000  \nunique            NaN  \ntop               NaN  \nfreq              NaN  \nmean         0.871968  \nstd          0.258633  \nmin          0.000000  \n25%          0.884929  \n50%          1.000000  \n75%          1.000000  \nmax          1.000000  \n\n[11 rows x 51 columns]\n\n\nSome observations from the summary statistics: - The treatment variable has a mean of 0.666813, indicating about two-thirds of the sample received a treatment letter.\n\nThe control variable has a mean of 0.333187, indicating one-third of the sample received the standard letter with no match.\nThe ratio2 (2:1 match) and ratio3 (3:1 match) indicators each have a mean of approximately 0.222, meaning about 22% of the sample received these specific matching offers.\nThe size25, size50, size100, and sizeno match threshold treatments each have means around 0.167, showing equal distribution across these four match threshold categories.\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nfrom scipy.stats import ttest_ind\n\n%pip install statsmodels\nimport statsmodels.formula.api as smf\nimport statsmodels.api as sm\n\nRequirement already satisfied: statsmodels in /home/jovyan/.rsm-msba/lib/python3.11/site-packages (0.14.4)\nRequirement already satisfied: numpy&lt;3,&gt;=1.22.3 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (1.26.4)\nRequirement already satisfied: scipy!=1.9.2,&gt;=1.8 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (1.12.0)\nRequirement already satisfied: pandas!=2.1.0,&gt;=1.4 in /home/jovyan/.rsm-msba/lib/python3.11/site-packages (from statsmodels) (2.2.3)\nRequirement already satisfied: patsy&gt;=0.5.6 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (0.5.6)\nRequirement already satisfied: packaging&gt;=21.3 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (24.1)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (2.9.0)\nRequirement already satisfied: pytz&gt;=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (2024.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from patsy&gt;=0.5.6-&gt;statsmodels) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\n# Add an intercept column to the DataFrame\ndf['intercept'] = 1\n\n# Ensure consistent data for both t-test and regression\nconsistent_data = df[['mrm2', 'treatment', 'control', 'intercept']].dropna()\n\n# Perform a t-test\ntreatment_group = consistent_data[consistent_data['treatment'] == 1]['mrm2']\ncontrol_group = consistent_data[consistent_data['control'] == 1]['mrm2']\nt_stat, p_value_ttest = ttest_ind(treatment_group, control_group, equal_var=False)\n\nprint(f\"T-test results:\")\nprint(f\"T-statistic: {t_stat:.4f}, P-value: {p_value_ttest:.4f}\")\n\n# Perform a linear regression\nmodel = sm.OLS(consistent_data['mrm2'], consistent_data[['intercept', 'treatment']])\nresults = model.fit()\n\nprint(\"\\nLinear Regression results:\")\nprint(results.summary())\n\n# Confirm the p-value matches\np_value_regression = results.pvalues['treatment']\nprint(f\"\\nP-value from regression: {p_value_regression:.4f}\")\nassert abs(p_value_ttest - p_value_regression) &lt; 1e-3, \"P-values do not match!\"\n\nT-test results:\nT-statistic: 0.1195, P-value: 0.9049\n\nLinear Regression results:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   mrm2   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01428\nDate:                Wed, 28 May 2025   Prob (F-statistic):              0.905\nTime:                        14:07:09   Log-Likelihood:            -1.9585e+05\nNo. Observations:               50082   AIC:                         3.917e+05\nDf Residuals:                   50080   BIC:                         3.917e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept     12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\nOmnibus:                     8031.352   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\nSkew:                           1.163   Prob(JB):                         0.00\nKurtosis:                       3.751   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nP-value from regression: 0.9049"
  },
  {
    "objectID": "projects/homework1/hw1_questions.html#experimental-results",
    "href": "projects/homework1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib.pyplot as plt\n\n# Calculate the proportion of people who donated in each group\ntreatment_proportion = df[df['treatment'] == 1]['gave'].mean()\ncontrol_proportion = df[df['control'] == 1]['gave'].mean()\n\n# Create the barplot\nplt.bar(['Treatment', 'Control'], [treatment_proportion, control_proportion], color=['blue', 'orange'])\nplt.ylabel('Proportion of People Who Donated')\nplt.title('Proportion of Donors by Group')\n# Display the proportions\nprint(f\"Proportion of people who donated in the Treatment group: {treatment_proportion:.2%}\")\nprint(f\"Proportion of people who donated in the Control group: {control_proportion:.2%}\")\n\nplt.show()\n\nProportion of people who donated in the Treatment group: 2.20%\nProportion of people who donated in the Control group: 1.79%\n\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import ttest_ind\n\n%pip install statsmodels\nimport statsmodels.formula.api as smf\nimport statsmodels.api as sm\n\nRequirement already satisfied: statsmodels in /home/jovyan/.rsm-msba/lib/python3.11/site-packages (0.14.4)\nRequirement already satisfied: numpy&lt;3,&gt;=1.22.3 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (1.26.4)\nRequirement already satisfied: scipy!=1.9.2,&gt;=1.8 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (1.12.0)\nRequirement already satisfied: pandas!=2.1.0,&gt;=1.4 in /home/jovyan/.rsm-msba/lib/python3.11/site-packages (from statsmodels) (2.2.3)\nRequirement already satisfied: patsy&gt;=0.5.6 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (0.5.6)\nRequirement already satisfied: packaging&gt;=21.3 in /opt/conda/lib/python3.11/site-packages (from statsmodels) (24.1)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (2.9.0)\nRequirement already satisfied: pytz&gt;=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas!=2.1.0,&gt;=1.4-&gt;statsmodels) (2024.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from patsy&gt;=0.5.6-&gt;statsmodels) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n\n\n\nimport statsmodels.api as sm\n\n# Add an intercept column to the DataFrame\ndf['intercept'] = 1\n\n# Perform a bivariate linear regression\nbivariate_model = sm.OLS(df['gave'], df[['intercept', 'treatment']])\nbivariate_results = bivariate_model.fit()\n\nprint(\"\\nBivariate Linear Regression results:\")\nprint(bivariate_results.summary())\n\n# Extract the p-value for the treatment variable\nbivariate_p_value = bivariate_results.pvalues['treatment']\nprint(f\"\\nP-value for treatment in bivariate regression: {bivariate_p_value:.4f}\")\n\n\nBivariate Linear Regression results:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Wed, 28 May 2025   Prob (F-statistic):            0.00193\nTime:                        14:07:11   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nP-value for treatment in bivariate regression: 0.0019\n\n\n\n# Perform a probit regression\nprobit_model = smf.probit('gave ~ treatment', data=df)\nprobit_results = probit_model.fit()\n\n# Display the summary of the probit regression\nprint(\"\\nProbit Regression results:\")\nprint(probit_results.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\nProbit Regression results:\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 28 May 2025   Pseudo R-squ.:               0.0009783\nTime:                        14:07:13   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\nNotes: [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nP-value for treatment in bivariate regression: 0.0019\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n# Extract unique match ratios\nmatch_ratios = df['ratio'].unique()\n\n# Perform pairwise t-tests between match ratios\nfor i in range(len(match_ratios)):\n    for j in range(i + 1, len(match_ratios)):\n        ratio1 = match_ratios[i]\n        ratio2 = match_ratios[j]\n        \n        # Filter data for the two match ratios\n        group1 = df[df['ratio'] == ratio1]['gave'].dropna()\n        group2 = df[df['ratio'] == ratio2]['gave'].dropna()\n        \n        # Perform t-test\n        t_stat, p_value = ttest_ind(group1, group2, equal_var=False)\n        \n        # Print results\n        print(f\"T-test between match ratios {ratio1} and {ratio2}:\")\n        print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\\n\")\n\nT-test between match ratios Control and 1:\nT-statistic: -1.7046, P-value: 0.0883\n\nT-test between match ratios Control and 2:\nT-statistic: -2.7396, P-value: 0.0062\n\nT-test between match ratios Control and 3:\nT-statistic: -2.7926, P-value: 0.0052\n\nT-test between match ratios 1 and 2:\nT-statistic: -0.9650, P-value: 0.3345\n\nT-test between match ratios 1 and 3:\nT-statistic: -1.0150, P-value: 0.3101\n\nT-test between match ratios 2 and 3:\nT-statistic: -0.0501, P-value: 0.9600\n\n\n\n\n# Create the variable `ratio1` from the `ratio` column\ndf['ratio1'] = (df['ratio'] == 1).astype(int)\n\n# Perform the regression\nregression_model = sm.OLS(df['gave'], df[['intercept', 'ratio1', 'ratio2', 'ratio3']])\nregression_results = regression_model.fit()\n\n# Display the regression results\nprint(\"\\nRegression results:\")\nprint(regression_results.summary())\n\n\nRegression results:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.665\nDate:                Wed, 28 May 2025   Prob (F-statistic):             0.0118\nTime:                        14:07:13   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50079   BIC:                        -5.322e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept      0.0179      0.001     16.225      0.000       0.016       0.020\nratio1         0.0029      0.002      1.661      0.097      -0.001       0.006\nratio2         0.0048      0.002      2.744      0.006       0.001       0.008\nratio3         0.0049      0.002      2.802      0.005       0.001       0.008\n==============================================================================\nOmnibus:                    59812.754   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4316693.217\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.438   Cond. No.                         4.26\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n# Directly from the data\nresponse_rate_1_1 = df[df['ratio'] == 1]['gave'].mean()\nresponse_rate_2_1 = df[df['ratio'] == 2]['gave'].mean()\nresponse_rate_3_1 = df[df['ratio'] == 3]['gave'].mean()\n\ndifference_1_1_2_1 = response_rate_1_1 - response_rate_2_1\ndifference_2_1_3_1 = response_rate_2_1 - response_rate_3_1\n\nprint(f\"Response rate difference (1:1 - 2:1): {difference_1_1_2_1:.4f}\")\nprint(f\"Response rate difference (2:1 - 3:1): {difference_2_1_3_1:.4f}\")\n\n# Using fitted coefficients from the regression\ncoefficients = regression_results.params\ndifference_1_1_2_1_coeff = coefficients[1]  # Coefficient for ratio 2\ndifference_2_1_3_1_coeff = coefficients[2] - coefficients[1]  # Difference between coefficients for ratio 3 and ratio 2\n\nprint(f\"Response rate difference from coefficients (1:1 - 2:1): {difference_1_1_2_1_coeff:.4f}\")\nprint(f\"Response rate difference from coefficients (2:1 - 3:1): {difference_2_1_3_1_coeff:.4f}\")\n\nResponse rate difference (1:1 - 2:1): -0.0019\nResponse rate difference (2:1 - 3:1): -0.0001\nResponse rate difference from coefficients (1:1 - 2:1): 0.0029\nResponse rate difference from coefficients (2:1 - 3:1): 0.0019\n\n\n/tmp/ipykernel_4319/298916022.py:14: FutureWarning:\n\nSeries.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n\n/tmp/ipykernel_4319/298916022.py:15: FutureWarning:\n\nSeries.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n\n\n\nIncreasing donation match ratios from 1:1 to 2:1 slightly boosts response rates, but moving from 2:1 to 3:1 offers minimal additional impact. Response rates rise from 2.07% (1:1) to 2.26% (2:1) and only slightly to 2.27% (3:1), with diminishing returns evident in both response differences and regression coefficients. This suggests that while a moderate increase in match size can be effective, higher ratios beyond 2:1 may not significantly enhance donor motivation.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n# Perform a bivariate linear regression of donation amount on treatment status\nbivariate_amount_model = sm.OLS(df['amount'], df[['intercept', 'treatment']])\nbivariate_amount_results = bivariate_amount_model.fit()\n\n# Display the regression results\nprint(\"\\nBivariate Linear Regression results for donation amount on treatment status:\")\nprint(bivariate_amount_results.summary())\n\n\nBivariate Linear Regression results for donation amount on treatment status:\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.461\nDate:                Wed, 28 May 2025   Prob (F-statistic):             0.0628\nTime:                        14:07:13   Log-Likelihood:            -1.7946e+05\nNo. Observations:               50083   AIC:                         3.589e+05\nDf Residuals:                   50081   BIC:                         3.589e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\nOmnibus:                    96861.113   Durbin-Watson:                   2.008\nProb(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\nSkew:                          15.297   Prob(JB):                         0.00\nKurtosis:                     341.269   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nObservations:\nEffect of Treatment on Donation Amount: The coefficient for the treatment variable is 0.1536, indicating that being in the treatment group (e.g., exposed to a donation match offer) is associated with an increase of approximately $0.15 in the average donation amount. However, this effect is not statistically significant at the conventional 5% level (p = 0.063), suggesting we cannot confidently conclude that treatment has a real impact on donation amount.\nModel Fit: The R-squared value is 0.000, indicating that the model explains virtually none of the variation in donation amount. This is common in social science data but implies that other factors (beyond just treatment status) are likely influencing donation amounts.\nStatistical Significance: While the p-value for the treatment variable (0.063) is close to 0.05, it slightly exceeds it, meaning the result is only marginally significant. This suggests a possible, but weak, effect of treatment on donation amount that might warrant further investigation with a larger sample or additional controls.\nBaseline Donation Amount: The intercept is 0.8133, indicating that individuals in the control group donated around $0.81 on average.\n\n# Filter the data to include only people who made a donation\ndonors_df = df[df['gave'] == 1]\n\n# Perform a bivariate linear regression of donation amount on treatment status for donors\nbivariate_donors_model = sm.OLS(donors_df['amount'], donors_df[['intercept', 'treatment']])\nbivariate_donors_results = bivariate_donors_model.fit()\n\n# Display the regression results\nprint(\"\\nBivariate Linear Regression results for donation amount on treatment status (donors only):\")\nprint(bivariate_donors_results.summary())\n\n\nBivariate Linear Regression results for donation amount on treatment status (donors only):\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Wed, 28 May 2025   Prob (F-statistic):              0.561\nTime:                        14:07:13   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nInterpretations:\n\nDonors in the treatment group gave about $1.67 less on average than those in the control group. However, this difference is not statistically significant (p-value = 0.561), meaning we can’t confidently say it’s a real effect.\nThere’s no strong evidence that treatment affects the amount donated, conditional on donating.\nThe treatment coefficient should not be interpreted causally because the sample is restricted to donors only.\nTreatment could influence both whether someone donates and how much they give. By only analyzing donors, we’re conditioning on a post-treatment outcome, which can lead to biased estimates (known as collider bias).\n\n\nimport matplotlib.pyplot as plt\n\n# Filter donation amounts for treatment and control groups among donors\ntreatment_donations = donors_df[donors_df['treatment'] == 1]['amount']\ncontrol_donations = donors_df[donors_df['control'] == 1]['amount']\n\n# Calculate the sample averages\ntreatment_avg = treatment_donations.mean()\ncontrol_avg = control_donations.mean()\n\n# Create the histograms\nfig, axes = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n\n# Treatment group histogram\naxes[0].hist(treatment_donations, bins=30, color='blue', alpha=0.7, edgecolor='black')\naxes[0].axvline(treatment_avg, color='red', linestyle='--', label=f'Avg: {treatment_avg:.2f}')\naxes[0].set_title('Treatment Group')\naxes[0].set_xlabel('Donation Amount')\naxes[0].set_ylabel('Frequency')\naxes[0].legend()\n\n# Control group histogram\naxes[1].hist(control_donations, bins=30, color='green', alpha=0.7, edgecolor='black')\naxes[1].axvline(control_avg, color='red', linestyle='--', label=f'Avg: {control_avg:.2f}')\naxes[1].set_title('Control Group')\naxes[1].set_xlabel('Donation Amount')\naxes[1].legend()\n\n# Display the plots\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects/homework1/hw1_questions.html#simulation-experiment",
    "href": "projects/homework1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\n# Parameters\np_no_match = 0.018  # Probability of donation without match\np_with_match = 0.022  # Probability of donation with match\nsample_sizes = [10, 50, 100, 500, 1000, 5000, 10000]  # Different sample sizes\nnum_simulations = 1000  # Number of simulations for CLT\n\n# Law of Large Numbers (LLN)\nmeans_no_match = []\nmeans_with_match = []\n\nfor size in sample_sizes:\n    sample_no_match = np.random.binomial(1, p_no_match, size)\n    sample_with_match = np.random.binomial(1, p_with_match, size)\n    means_no_match.append(np.mean(sample_no_match))\n    means_with_match.append(np.mean(sample_with_match))\n\n# Plot LLN\nplt.figure(figsize=(12, 6))\nplt.plot(sample_sizes, means_no_match, label=\"No Match (p=0.018)\", marker='o')\nplt.plot(sample_sizes, means_with_match, label=\"With Match (p=0.022)\", marker='o')\nplt.axhline(y=p_no_match, color='blue', linestyle='--', label=\"True Mean (No Match)\")\nplt.axhline(y=p_with_match, color='orange', linestyle='--', label=\"True Mean (With Match)\")\nplt.xlabel(\"Sample Size\")\nplt.ylabel(\"Sample Mean\")\nplt.title(\"Law of Large Numbers\")\nplt.legend()\nplt.grid()\nplt.show()\n\n# Central Limit Theorem (CLT)\nsample_means_no_match = []\nsample_means_with_match = []\n\nfor _ in range(num_simulations):\n    sample_no_match = np.random.binomial(1, p_no_match, 1000)  # Fixed sample size\n    sample_with_match = np.random.binomial(1, p_with_match, 1000)\n    sample_means_no_match.append(np.mean(sample_no_match))\n    sample_means_with_match.append(np.mean(sample_with_match))\n\n# Plot CLT\nplt.figure(figsize=(12, 6))\nplt.hist(sample_means_no_match, bins=30, alpha=0.7, label=\"No Match (p=0.018)\", color='blue', edgecolor='black')\nplt.hist(sample_means_with_match, bins=30, alpha=0.7, label=\"With Match (p=0.022)\", color='orange', edgecolor='black')\nplt.axvline(x=p_no_match, color='blue', linestyle='--', label=\"True Mean (No Match)\")\nplt.axvline(x=p_with_match, color='orange', linestyle='--', label=\"True Mean (With Match)\")\nplt.xlabel(\"Sample Mean\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Central Limit Theorem\")\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLaw of Large Numbers\n\nimport numpy as np\n\n# Filter the control group\ncontrol_amounts = df[df['control'] == 1]['amount']\n\n# Simulate 100,000 draws from the control distribution\nsimulated_draws = np.random.choice(control_amounts, size=100000, replace=True)\n\n# Display summary statistics of the simulated draws\nprint(f\"Simulated Draws Summary:\")\nprint(f\"Mean: {np.mean(simulated_draws):.4f}\")\nprint(f\"Standard Deviation: {np.std(simulated_draws):.4f}\")\nprint(f\"Min: {np.min(simulated_draws):.4f}\")\nprint(f\"Max: {np.max(simulated_draws):.4f}\")\n\nSimulated Draws Summary:\nMean: 0.7652\nStandard Deviation: 7.7980\nMin: 0.0000\nMax: 300.0000\n\n\n\n# Filter the treatment group\ntreatment_amounts = df[df['treatment'] == 1]['amount']\n\n# Simulate 10,000 draws from the treatment distribution\nsimulated_treatment_draws = np.random.choice(treatment_amounts, size=10000, replace=True)\n\n# Display summary statistics of the simulated treatment draws\nprint(f\"Simulated Treatment Draws Summary:\")\nprint(f\"Mean: {np.mean(simulated_treatment_draws):.4f}\")\nprint(f\"Standard Deviation: {np.std(simulated_treatment_draws):.4f}\")\nprint(f\"Min: {np.min(simulated_treatment_draws):.4f}\")\nprint(f\"Max: {np.max(simulated_treatment_draws):.4f}\")\n\nSimulated Treatment Draws Summary:\nMean: 1.0663\nStandard Deviation: 9.6326\nMin: 0.0000\nMax: 400.0000\n\n\n\n# Simulate 100,000 draws from the control distribution\nsimulated_control_draws = np.random.choice(control_amounts, size=100000, replace=True)\n\n# Simulate 10,000 draws from the treatment distribution\nsimulated_treatment_draws = np.random.choice(treatment_amounts, size=10000, replace=True)\n\n# Calculate a vector of 10,000 differences\ndifferences = simulated_treatment_draws - simulated_control_draws[:10000]\n\n# Calculate the cumulative average of the differences\ncumulative_avg = np.cumsum(differences) / np.arange(1, len(differences) + 1)\n\n# Plot the cumulative average\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_avg, label=\"Cumulative Average of Differences\")\nplt.axhline(0, color='red', linestyle='--', label=\"Zero Line\")\nplt.xlabel(\"Number of Differences\")\nplt.ylabel(\"Cumulative Average\")\nplt.title(\"Cumulative Average of Differences Between Treatment and Control\")\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import norm\n\n# Add a distribution curve to the plot\n# Fit a normal distribution to the differences\nmean_diff = np.mean(differences)\nstd_diff = np.std(differences)\n\n# Generate x values for the curve\nx = np.linspace(min(differences), max(differences), 1000)\ny = norm.pdf(x, mean_diff, std_diff)\n\n# Plot the distribution curve\nplt.figure(figsize=(10, 6))\nplt.plot(x, y, label=\"Normal Distribution Curve\", color='purple')\nplt.hist(differences, bins=50, density=True, alpha=0.6, color='gray', edgecolor='black')\nplt.axvline(0, color='red', linestyle='--', label=\"Zero Line\")\nplt.xlabel(\"Differences\")\nplt.ylabel(\"Density\")\nplt.title(\"Distribution of Differences with Fitted Curve\")\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\n\nimport numpy as np\n\n# Set the number of draws and repetitions\nsample_size = 50\nnum_repetitions = 1000\n\n# Initialize a list to store the average differences\naverage_differences = []\n\n# Perform the simulation\nfor _ in range(num_repetitions):\n    # Take random draws from the control and treatment distributions\n    control_sample = np.random.choice(control_amounts, size=sample_size, replace=True)\n    treatment_sample = np.random.choice(treatment_amounts, size=sample_size, replace=True)\n    \n    # Calculate the average difference and store it\n    avg_diff = np.mean(treatment_sample) - np.mean(control_sample)\n    average_differences.append(avg_diff)\n\n# Plot the histogram of the average differences\nplt.figure(figsize=(10, 6))\nplt.hist(average_differences, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\nplt.axvline(np.mean(average_differences), color='red', linestyle='--', label=f'Mean: {np.mean(average_differences):.4f}')\nplt.xlabel('Average Difference')\nplt.ylabel('Frequency')\nplt.title('Histogram of Average Differences for a Sample Size of 50')\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\nAt a sample size of 50, the distribution of average differences is wide and variable. The mean is around 0.174, suggesting a positive treatment effect, but the high variance means zero still lies relatively close to the center. With this small sample, the result is noisy, and we cannot confidently reject the possibility that the true effect is zero.\n\n# Set the number of draws and repetitions\nsample_size = 200\nnum_repetitions = 1000\n\n# Initialize a list to store the average differences\naverage_differences = []\n\n# Perform the simulation\nfor _ in range(num_repetitions):\n    # Take random draws from the control and treatment distributions\n    control_sample = np.random.choice(control_amounts, size=sample_size, replace=True)\n    treatment_sample = np.random.choice(treatment_amounts, size=sample_size, replace=True)\n    \n    # Calculate the average difference and store it\n    avg_diff = np.mean(treatment_sample) - np.mean(control_sample)\n    average_differences.append(avg_diff)\n\n# Plot the histogram of the average differences\nplt.figure(figsize=(10, 6))\nplt.hist(average_differences, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\nplt.axvline(np.mean(average_differences), color='red', linestyle='--', label=f'Mean: {np.mean(average_differences):.4f}')\nplt.xlabel('Average Difference')\nplt.ylabel('Frequency')\nplt.title('Histogram of Average Differences for a Sample Size of 200')\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\nWhen the sample size increases to 200, the distribution tightens, and the average difference remains positive at about 0.191. Zero begins to move away from the center but still lies within a range where random variation could plausibly explain the observed differences.\n\n# Set the sample size and number of repetitions\nsample_size = 500\nnum_repetitions = 1000\n\n# Initialize a list to store the average differences\naverage_differences = []\n\n# Perform the simulation\nfor _ in range(num_repetitions):\n    # Take random draws from the control and treatment distributions\n    control_sample = np.random.choice(control_amounts, size=sample_size, replace=True)\n    treatment_sample = np.random.choice(treatment_amounts, size=sample_size, replace=True)\n    \n    # Calculate the average difference and store it\n    avg_diff = np.mean(treatment_sample) - np.mean(control_sample)\n    average_differences.append(avg_diff)\n\n# Plot the histogram of the average differences\nplt.figure(figsize=(10, 6))\nplt.hist(average_differences, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\nplt.axvline(np.mean(average_differences), color='red', linestyle='--', label=f'Mean: {np.mean(average_differences):.4f}')\nplt.xlabel('Average Difference')\nplt.ylabel('Frequency')\nplt.title('Histogram of Average Differences for a Sample Size of 500')\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\nAt a sample size of 500, the distribution becomes more concentrated, and the mean difference of 0.156 shows less variability. Zero is no longer near the middle and starts to appear in the tails. This suggests a stronger signal from the treatment, with less influence from random noise.\n\n# Set the number of draws and repetitions\n# Set the sample size and number of repetitions\nsample_size = 1000\nnum_repetitions = 1000\n\n# Initialize a list to store the average differences\naverage_differences = []\n\n# Perform the simulation\nfor _ in range(num_repetitions):\n    # Take random draws from the control and treatment distributions\n    control_sample = np.random.choice(control_amounts, size=sample_size, replace=True)\n    treatment_sample = np.random.choice(treatment_amounts, size=sample_size, replace=True)\n    \n    # Calculate the average difference and store it\n    avg_diff = np.mean(treatment_sample) - np.mean(control_sample)\n    average_differences.append(avg_diff)\n\n# Plot the histogram of the average differences\nplt.figure(figsize=(10, 6))\nplt.hist(average_differences, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\nplt.axvline(np.mean(average_differences), color='red', linestyle='--', label=f'Mean: {np.mean(average_differences):.4f}')\nplt.xlabel('Average Difference')\nplt.ylabel('Frequency')\nplt.title('Histogram of Average Differences for a Sample Size of 1000')\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\nBy the time the sample size reaches 1000, the distribution is narrow and centered near 0.151. Zero is clearly in the tail, and the likelihood of observing such differences under the null is small. This provides strong evidence of a treatment effect.\nImportantly, zero moves from the center toward the tails of the distribution and eventually falls outside the typical range of differences we’d expect if there were no treatment effect.\nTogether, the histograms suggest that the treatment group performs better than the control group, and that this observed difference is unlikely to be due to random variation—especially at larger sample sizes. This supports the conclusion that the treatment has a real, measurable effect."
  },
  {
    "objectID": "projects/homework1/hw3_questions.html",
    "href": "projects/homework1/hw3_questions.html",
    "title": "Multinomial Logit Model",
    "section": "",
    "text": "This assignment expores two methods for estimating the MNL model: (1) via Maximum Likelihood, and (2) via a Bayesian approach using a Metropolis-Hastings MCMC algorithm."
  },
  {
    "objectID": "projects/homework1/hw3_questions.html#likelihood-for-the-multi-nomial-logit-mnl-model",
    "href": "projects/homework1/hw3_questions.html#likelihood-for-the-multi-nomial-logit-mnl-model",
    "title": "Multinomial Logit Model",
    "section": "1. Likelihood for the Multi-nomial Logit (MNL) Model",
    "text": "1. Likelihood for the Multi-nomial Logit (MNL) Model\nSuppose we have \\(i=1,\\ldots,n\\) consumers who each select exactly one product \\(j\\) from a set of \\(J\\) products. The outcome variable is the identity of the product chosen \\(y_i \\in \\{1, \\ldots, J\\}\\) or equivalently a vector of \\(J-1\\) zeros and \\(1\\) one, where the \\(1\\) indicates the selected product. For example, if the third product was chosen out of 3 products, then either \\(y=3\\) or \\(y=(0,0,1)\\) depending on how we want to represent it. Suppose also that we have a vector of data on each product \\(x_j\\) (eg, brand, price, etc.).\nWe model the consumer’s decision as the selection of the product that provides the most utility, and we’ll specify the utility function as a linear function of the product characteristics:\n\\[ U_{ij} = x_j'\\beta + \\epsilon_{ij} \\]\nwhere \\(\\epsilon_{ij}\\) is an i.i.d. extreme value error term.\nThe choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer \\(i\\) chooses product \\(j\\):\n\\[ \\mathbb{P}_i(j) = \\frac{e^{x_j'\\beta}}{\\sum_{k=1}^Je^{x_k'\\beta}} \\]\nFor example, if there are 3 products, the probability that consumer \\(i\\) chooses product 3 is:\n\\[ \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{e^{x_1'\\beta} + e^{x_2'\\beta} + e^{x_3'\\beta}} \\]\nA clever way to write the individual likelihood function for consumer \\(i\\) is the product of the \\(J\\) probabilities, each raised to the power of an indicator variable (\\(\\delta_{ij}\\)) that indicates the chosen product:\n\\[ L_i(\\beta) = \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} = \\mathbb{P}_i(1)^{\\delta_{i1}} \\times \\ldots \\times \\mathbb{P}_i(J)^{\\delta_{iJ}}\\]\nNotice that if the consumer selected product \\(j=3\\), then \\(\\delta_{i3}=1\\) while \\(\\delta_{i1}=\\delta_{i2}=0\\) and the likelihood is:\n\\[ L_i(\\beta) = \\mathbb{P}_i(1)^0 \\times \\mathbb{P}_i(2)^0 \\times \\mathbb{P}_i(3)^1 = \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{\\sum_{k=1}^3e^{x_k'\\beta}} \\]\nThe joint likelihood (across all consumers) is the product of the \\(n\\) individual likelihoods:\n\\[ L_n(\\beta) = \\prod_{i=1}^n L_i(\\beta) = \\prod_{i=1}^n \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} \\]\nAnd the joint log-likelihood function is:\n\\[ \\ell_n(\\beta) = \\sum_{i=1}^n \\sum_{j=1}^J \\delta_{ij} \\log(\\mathbb{P}_i(j)) \\]"
  },
  {
    "objectID": "projects/homework1/hw3_questions.html#simulate-conjoint-data",
    "href": "projects/homework1/hw3_questions.html#simulate-conjoint-data",
    "title": "Multinomial Logit Model",
    "section": "2. Simulate Conjoint Data",
    "text": "2. Simulate Conjoint Data\nWe will simulate data from a conjoint experiment about video content streaming services. We elect to simulate 100 respondents, each completing 10 choice tasks, where they choose from three alternatives per task. For simplicity, there is not a “no choice” option; each simulated respondent must select one of the 3 alternatives.\nEach alternative is a hypothetical streaming offer consistent of three attributes: (1) brand is either Netflix, Amazon Prime, or Hulu; (2) ads can either be part of the experience, or it can be ad-free, and (3) price per month ranges from $4 to $32 in increments of $4.\nThe part-worths (ie, preference weights or beta parameters) for the attribute levels will be 1.0 for Netflix, 0.5 for Amazon Prime (with 0 for Hulu as the reference brand); -0.8 for included adverstisements (0 for ad-free); and -0.1*price so that utility to consumer \\(i\\) for hypothethical streaming service \\(j\\) is\n\\[\nu_{ij} = (1 \\times Netflix_j) + (0.5 \\times Prime_j) + (-0.8*Ads_j) - 0.1\\times Price_j + \\varepsilon_{ij}\n\\]\nwhere the variables are binary indicators and \\(\\varepsilon\\) is Type 1 Extreme Value (ie, Gumble) distributed.\nThe following code provides the simulation of the conjoint data. :::: {.callout-note collapse=“true”}\n\nimport numpy as np\nimport pandas as pd\n\n# Set seed for reproducibility\nnp.random.seed(123)\n\n# Define attributes\nbrand = [\"N\", \"P\", \"H\"]  # Netflix, Prime, Hulu\nad = [\"Yes\", \"No\"]\nprice = np.arange(8, 33, 4)  # $8 to $32 in $4 increments\n\n# Generate all possible profiles\nprofiles = pd.DataFrame([\n    {'brand': b, 'ad': a, 'price': p}\n    for b in brand for a in ad for p in price\n])\nm = profiles.shape[0]\n\n# Part-worth utilities (true parameters)\nb_util = {\"N\": 1.0, \"P\": 0.5, \"H\": 0}\na_util = {\"Yes\": -0.8, \"No\": 0.0}\np_util = lambda p: -0.1 * p\n\n# Configuration\nn_peeps = 100\nn_tasks = 10\nn_alts = 3\n\n# Function to simulate one respondent’s data\ndef sim_one(id_):\n    all_tasks = []\n    for t in range(1, n_tasks + 1):\n        sampled = profiles.sample(n=n_alts).copy()\n        sampled[\"resp\"] = id_\n        sampled[\"task\"] = t\n        sampled[\"v\"] = (\n            sampled[\"brand\"].map(b_util) +\n            sampled[\"ad\"].map(a_util) +\n            p_util(sampled[\"price\"])\n        )\n        # Add Gumbel (Type I Extreme Value) noise\n        gumbel_noise = -np.log(-np.log(np.random.uniform(size=n_alts)))\n        sampled[\"u\"] = sampled[\"v\"] + gumbel_noise\n        sampled[\"choice\"] = (sampled[\"u\"] == sampled[\"u\"].max()).astype(int)\n        all_tasks.append(sampled)\n\n    return pd.concat(all_tasks)\n\n# Simulate data for all respondents\nconjoint_data = pd.concat([sim_one(i) for i in range(1, n_peeps + 1)])\n\n# Keep only observable variables\nconjoint_data = conjoint_data[[\"resp\", \"task\", \"brand\", \"ad\", \"price\", \"choice\"]]\n\nconjoint_data.head()\n\n\n\n\n\n\n\n\nresp\ntask\nbrand\nad\nprice\nchoice\n\n\n\n\n27\n1\n1\nP\nNo\n32\n0\n\n\n12\n1\n1\nN\nNo\n28\n0\n\n\n11\n1\n1\nN\nNo\n24\n1\n\n\n40\n1\n2\nH\nNo\n28\n0\n\n\n35\n1\n2\nH\nNo\n8\n1"
  },
  {
    "objectID": "projects/homework1/hw3_questions.html#estimation-via-maximum-likelihood",
    "href": "projects/homework1/hw3_questions.html#estimation-via-maximum-likelihood",
    "title": "Multinomial Logit Model",
    "section": "4. Estimation via Maximum Likelihood",
    "text": "4. Estimation via Maximum Likelihood\n\nfrom scipy.optimize import minimize\n\n# Define the MNL log-likelihood function\ndef mnl_log_likelihood(beta, X, y):\n    \"\"\"\n    Multinomial Logit Log-Likelihood Function\n    :param beta: Coefficients (array-like)\n    :param X: Covariates (n x k matrix)\n    :param y: Choices (binary vector of length n)\n    :return: Negative log-likelihood (to minimize)\n    \"\"\"\n    utilities = X @ beta  # Linear combination of covariates and coefficients\n    exp_utilities = np.exp(utilities)  # Exponentiate utilities\n    probabilities = exp_utilities / exp_utilities.sum(axis=0)  # Normalize probabilities\n    log_probabilities = np.log(probabilities)\n    log_likelihood = np.sum(y * log_probabilities)  # Log-likelihood\n    return -log_likelihood  # Negative log-likelihood for minimization\n\n# Initial guesses for beta coefficients\ninitial_beta = np.zeros(X.shape[1])\n\n# Set up and run the optimizer\nresult = minimize(\n    fun=mnl_log_likelihood,\n    x0=initial_beta,\n    args=(X, y),\n    method='BFGS'\n)\n\n# Extract results\nestimated_beta = result.x\nlog_likelihood_at_optimum = -result.fun\n\n# Label the estimated coefficients\nparameters = ['beta_netflix', 'beta_prime', 'beta_ads', 'beta_price']\nresults = pd.DataFrame({\n    'Parameter': parameters,\n    'Estimate': estimated_beta\n})\n\n# Print results\nprint(results)\nprint(f\"Log-Likelihood at Optimum: {log_likelihood_at_optimum}\")\n\n      Parameter  Estimate\n0  beta_netflix  0.589257\n1    beta_prime  0.309896\n2      beta_ads -0.431235\n3    beta_price -0.057604\nLog-Likelihood at Optimum: -7854.729636838663\n\n\n\n# Calculate standard errors and confidence intervals\nhessian_inv = result.hess_inv  # Inverse Hessian matrix\nstandard_errors = np.sqrt(np.diag(hessian_inv))  # Standard errors from diagonal of Hessian\n\n# Construct 95% confidence intervals\nconfidence_intervals = [\n    (est - 1.96 * se, est + 1.96 * se)\n    for est, se in zip(estimated_beta, standard_errors)\n]\n\n# Combine results into a DataFrame\nresults = pd.DataFrame({\n    'Parameter': parameters,\n    'Estimate': estimated_beta,\n    'Std. Error': standard_errors,\n    '95% CI Lower': [ci[0] for ci in confidence_intervals],\n    '95% CI Upper': [ci[1] for ci in confidence_intervals]\n})\n\n# Print results\nprint(results)\n\n      Parameter  Estimate  Std. Error  95% CI Lower  95% CI Upper\n0  beta_netflix  0.589257    0.079246      0.433935      0.744579\n1    beta_prime  0.309896    0.084095      0.145070      0.474722\n2      beta_ads -0.431235    0.064686     -0.558019     -0.304450\n3    beta_price -0.057604    0.004182     -0.065801     -0.049408\n\n\nThe output provides a detailed summary of the maximum likelihood estimates (MLEs) for four parameters in the Multinomial Logit (MNL) model, along with their standard errors and 95% confidence intervals. These estimates quantify how different attributes (streaming service brand, ad presence, and price) influence the probability of a product being chosen.\n\nbeta_netflix: Holding other factors constant, choosing Netflix increases the utility of a product by approximately 0.59 units relative to the baseline brand (likely Hulu). The 95% confidence interval [0.434, 0.745] does not include 0, indicating the effect is statistically significant. The standard error (0.079) is relatively small, suggesting the estimate is precise. This reflects a strong preference for Netflix.\nbeta_prime: Choosing Amazon Prime increases utility by 0.31 units, again relative to the baseline. The 95% confidence interval [0.145, 0.475] excludes 0, indicating statistical significance. The standard error (0.084) is a bit higher than for Netflix but still moderate, suggesting the estimate is fairly precise. Prime is also preferred over the baseline, though less strongly than Netflix.\nbeta_ads: The presence of ads reduces the utility of a product by −0.43 units. The confidence interval [−0.558, −0.304] lies entirely below 0, indicating a statistically significant negative effect. The standard error (0.065) is small, confirming this is a robust and meaningful finding: ads detract from the product’s attractiveness.\nbeta_price: Each unit increase in price reduces utility by about −0.058 units. While this is the smallest effect in magnitude, the confidence interval [−0.066, −0.049] is extremely narrow and does not contain 0, indicating a very precise and statistically significant effect. This aligns with economic intuition: higher prices reduce utility.\n\nOverall, all four parameters are statistically significant, and the signs of the coefficients align with expected consumer preferences: consumers prefer Netflix and Prime over the baseline, dislike ads, and are sensitive to price increases."
  },
  {
    "objectID": "projects/homework1/hw3_questions.html#estimation-via-bayesian-methods",
    "href": "projects/homework1/hw3_questions.html#estimation-via-bayesian-methods",
    "title": "Multinomial Logit Model",
    "section": "5. Estimation via Bayesian Methods",
    "text": "5. Estimation via Bayesian Methods\ntodo: code up a metropolis-hasting MCMC sampler of the posterior distribution. Take 11,000 steps and throw away the first 1,000, retaining the subsequent 10,000.\n\nimport numpy as np\nimport pandas as pd\n\n# Define the log-prior function\ndef log_prior(beta):\n    \"\"\"\n    Log-prior for the coefficients.\n    :param beta: Coefficients (array-like)\n    :return: Log-prior value\n    \"\"\"\n    log_prior_beta = np.sum(-0.5 * (beta[:3] ** 2) / 5)  # N(0, 5) for binary variables\n    log_prior_price = -0.5 * (beta[3] ** 2) / 1          # N(0, 1) for price\n    return log_prior_beta + log_prior_price\n\n# Define the log-posterior function\ndef log_posterior(beta, X, y):\n    \"\"\"\n    Log-posterior function.\n    :param beta: Coefficients (array-like)\n    :param X: Covariates (n x k matrix)\n    :param y: Choices (binary vector of length n)\n    :return: Log-posterior value\n    \"\"\"\n    log_lik = -mnl_log_likelihood(beta, X, y)  # Log-likelihood\n    log_pr = log_prior(beta)                  # Log-prior\n    return log_lik + log_pr                   # Log-posterior\n\n# Metropolis-Hastings MCMC sampler\ndef metropolis_hastings(X, y, n_steps=11000, burn_in=1000):\n    \"\"\"\n    Metropolis-Hastings MCMC sampler.\n    :param X: Covariates (n x k matrix)\n    :param y: Choices (binary vector of length n)\n    :param n_steps: Total number of steps\n    :param burn_in: Number of steps to discard\n    :return: Posterior samples (after burn-in)\n    \"\"\"\n    # Initialize parameters\n    beta_current = np.zeros(X.shape[1])  # Start at zero\n    samples = []\n    \n    # Proposal distribution parameters\n    proposal_std = np.array([0.05, 0.05, 0.05, 0.005])  # Standard deviations\n    \n    for step in range(n_steps):\n        # Propose new beta values\n        beta_proposed = beta_current + np.random.normal(0, proposal_std)\n        \n        # Calculate log-posterior for current and proposed values\n        log_post_current = log_posterior(beta_current, X, y)\n        log_post_proposed = log_posterior(beta_proposed, X, y)\n        \n        # Acceptance probability\n        acceptance_prob = np.exp(log_post_proposed - log_post_current)\n        \n        # Accept or reject the proposal\n        if np.random.uniform(0, 1) &lt; acceptance_prob:\n            beta_current = beta_proposed\n        \n        # Store the sample\n        samples.append(beta_current)\n    \n    # Discard burn-in samples and return the rest\n    return np.array(samples[burn_in:])\n\n# Run the MCMC sampler\nposterior_samples = metropolis_hastings(X, y)\n\n# Analyze posterior samples\nposterior_means = posterior_samples.mean(axis=0)\nposterior_stds = posterior_samples.std(axis=0)\nposterior_cis = np.percentile(posterior_samples, [2.5, 97.5], axis=0)\n\n# Print results\nparameters = ['beta_netflix', 'beta_prime', 'beta_ads', 'beta_price']\nresults = pd.DataFrame({\n    'Parameter': parameters,\n    'Posterior Mean': posterior_means,\n    'Posterior Std. Dev': posterior_stds,\n    '95% CI Lower': posterior_cis[0],\n    '95% CI Upper': posterior_cis[1]\n})\nprint(results)\n\n      Parameter  Posterior Mean  Posterior Std. Dev  95% CI Lower  \\\n0  beta_netflix        0.585437            0.077570      0.436184   \n1    beta_prime        0.304957            0.084069      0.143503   \n2      beta_ads       -0.428348            0.066231     -0.559770   \n3    beta_price       -0.057625            0.004208     -0.066113   \n\n   95% CI Upper  \n0      0.734613  \n1      0.463256  \n2     -0.301122  \n3     -0.049414  \n\n\nhint: Use N(0,5) priors for the betas on the binary variables, and a N(0,1) prior for the price beta.\n_hint: instead of calculating post=lik*prior, you can work in the log-space and calculate log-post = log-lik + log-prior (this should enable you to re-use your log-likelihood function from the MLE section just above)_\nhint: King Markov (in the video) use a candidate distribution of a coin flip to decide whether to move left or right among his islands. Unlike King Markov, we have 4 dimensions (because we have 4 betas) and our dimensions are continuous. So, use a multivariate normal distribution to pospose the next location for the algorithm to move to. I recommend a MNV(mu, Sigma) where mu=c(0,0,0,0) and sigma has diagonal values c(0.05, 0.05, 0.05, 0.005) and zeros on the off-diagonal. Since this MVN has no covariances, you can sample each dimension independently (so 4 univariate normals instead of 1 multivariate normal), where the first 3 univariate normals are N(0,0.05) and the last one if N(0,0.005).\n\n# Define the log-prior function\ndef log_prior(beta):\n    \"\"\"\n    Log-prior for the coefficients.\n    :param beta: Coefficients (array-like)\n    :return: Log-prior value\n    \"\"\"\n    log_prior_beta = np.sum(-0.5 * (beta[:3] ** 2) / 5)  # N(0, 5) for binary variables\n    log_prior_price = -0.5 * (beta[3] ** 2) / 1          # N(0, 1) for price\n    return log_prior_beta + log_prior_price\n\n# Define the log-posterior function\ndef log_posterior(beta, X, y):\n    \"\"\"\n    Log-posterior function.\n    :param beta: Coefficients (array-like)\n    :param X: Covariates (n x k matrix)\n    :param y: Choices (binary vector of length n)\n    :return: Log-posterior value\n    \"\"\"\n    log_lik = -mnl_log_likelihood(beta, X, y)  # Log-likelihood\n    log_pr = log_prior(beta)                  # Log-prior\n    return log_lik + log_pr                   # Log-posterior\n\n# Metropolis-Hastings MCMC sampler\ndef metropolis_hastings(X, y, n_steps=11000, burn_in=1000):\n    \"\"\"\n    Metropolis-Hastings MCMC sampler.\n    :param X: Covariates (n x k matrix)\n    :param y: Choices (binary vector of length n)\n    :param n_steps: Total number of steps\n    :param burn_in: Number of steps to discard\n    :return: Posterior samples (after burn-in)\n    \"\"\"\n    # Initialize parameters\n    beta_current = np.zeros(X.shape[1])  # Start at zero\n    samples = []\n    \n    # Proposal distribution parameters\n    proposal_std = np.array([0.05, 0.05, 0.05, 0.005])  # Standard deviations\n    \n    for step in range(n_steps):\n        # Propose new beta values\n        beta_proposed = beta_current + np.random.normal(0, proposal_std)\n        \n        # Calculate log-posterior for current and proposed values\n        log_post_current = log_posterior(beta_current, X, y)\n        log_post_proposed = log_posterior(beta_proposed, X, y)\n        \n        # Acceptance probability\n        acceptance_prob = np.exp(log_post_proposed - log_post_current)\n        \n        # Accept or reject the proposal\n        if np.random.uniform(0, 1) &lt; acceptance_prob:\n            beta_current = beta_proposed\n        \n        # Store the sample\n        samples.append(beta_current)\n    \n    # Discard burn-in samples and return the rest\n    return np.array(samples[burn_in:])\n\n# Run the MCMC sampler\nposterior_samples = metropolis_hastings(X, y)\n\n# Analyze posterior samples\nposterior_means = posterior_samples.mean(axis=0)\nposterior_stds = posterior_samples.std(axis=0)\nposterior_cis = np.percentile(posterior_samples, [2.5, 97.5], axis=0)\n\n# Print results\nparameters = ['beta_netflix', 'beta_prime', 'beta_ads', 'beta_price']\nresults = pd.DataFrame({\n    'Parameter': parameters,\n    'Posterior Mean': posterior_means,\n    'Posterior Std. Dev': posterior_stds,\n    '95% CI Lower': posterior_cis[0],\n    '95% CI Upper': posterior_cis[1]\n})\nprint(results)\n\n# Trace plot for one parameter (e.g., beta_netflix)\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 6))\nplt.plot(posterior_samples[:, 0], alpha=0.7)\nplt.title(\"Trace Plot for beta_netflix\")\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"Value\")\nplt.show()\n\n# Histogram of posterior distribution for beta_netflix\nplt.figure(figsize=(10, 6))\nplt.hist(posterior_samples[:, 0], bins=30, alpha=0.7)\nplt.title(\"Posterior Distribution for beta_netflix\")\nplt.xlabel(\"Value\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n      Parameter  Posterior Mean  Posterior Std. Dev  95% CI Lower  \\\n0  beta_netflix        0.591909            0.081858      0.435550   \n1    beta_prime        0.313211            0.086864      0.146375   \n2      beta_ads       -0.433020            0.064819     -0.554352   \n3    beta_price       -0.057716            0.004224     -0.066231   \n\n   95% CI Upper  \n0      0.754660  \n1      0.487570  \n2     -0.305512  \n3     -0.049845  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntodo: for at least one of the 4 parameters, show the trace plot of the algorithm, as well as the histogram of the posterior distribution.\n\nimport matplotlib.pyplot as plt\n\n# Plot trace plots for all parameters\nparameters = ['beta_netflix', 'beta_prime', 'beta_ads', 'beta_price']\nfor i, param in enumerate(parameters):\n    plt.figure(figsize=(10, 6))\n    plt.plot(posterior_samples[:, i], alpha=0.7)\n    plt.title(f\"Trace Plot for {param}\")\n    plt.xlabel(\"Iteration\")\n    plt.ylabel(\"Value\")\n    plt.show()\n\n# Plot histograms for all parameters\nfor i, param in enumerate(parameters):\n    plt.figure(figsize=(10, 6))\n    plt.hist(posterior_samples[:, i], bins=30, alpha=0.7)\n    plt.title(f\"Posterior Distribution for {param}\")\n    plt.xlabel(\"Value\")\n    plt.ylabel(\"Frequency\")\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntodo: report the 4 posterior means, standard deviations, and 95% credible intervals and compare them to your results from the Maximum Likelihood approach.\n\n# Compare Bayesian posterior results to Maximum Likelihood estimates\ncomparison = pd.DataFrame({\n    'Parameter': parameters,\n    'MLE Estimate': estimated_beta,\n    'MLE Std. Error': standard_errors,\n    'Bayesian Posterior Mean': posterior_means,\n    'Bayesian Posterior Std. Dev': posterior_stds,\n    'Bayesian 95% CI Lower': posterior_cis[0],\n    'Bayesian 95% CI Upper': posterior_cis[1]\n})\n\nprint(comparison)\n\n      Parameter  MLE Estimate  MLE Std. Error  Bayesian Posterior Mean  \\\n0  beta_netflix      0.589257        0.079246                 0.591909   \n1    beta_prime      0.309896        0.084095                 0.313211   \n2      beta_ads     -0.431235        0.064686                -0.433020   \n3    beta_price     -0.057604        0.004182                -0.057716   \n\n   Bayesian Posterior Std. Dev  Bayesian 95% CI Lower  Bayesian 95% CI Upper  \n0                     0.081858               0.435550               0.754660  \n1                     0.086864               0.146375               0.487570  \n2                     0.064819              -0.554352              -0.305512  \n3                     0.004224              -0.066231              -0.049845"
  },
  {
    "objectID": "projects/homework1/hw3_questions.html#discussion",
    "href": "projects/homework1/hw3_questions.html#discussion",
    "title": "Multinomial Logit Model",
    "section": "6. Discussion",
    "text": "6. Discussion\ntodo: Suppose you did not simulate the data. What do you observe about the parameter estimates? What does \\(\\beta_\\text{Netflix} &gt; \\beta_\\text{Prime}\\) mean? Does it make sense that \\(\\beta_\\text{price}\\) is negative?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "anjanakhabir",
    "section": "",
    "text": "Welcome to my website!\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "projects/homework1/hw3_questions.html#preparing-the-data-for-estimation",
    "href": "projects/homework1/hw3_questions.html#preparing-the-data-for-estimation",
    "title": "Multinomial Logit Model",
    "section": "3. Preparing the Data for Estimation",
    "text": "3. Preparing the Data for Estimation\nThe “hard part” of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer \\(i\\), covariate \\(k\\), and product \\(j\\)) instead of the typical 2 dimensions for cross-sectional regression models (consumer \\(i\\) and covariate \\(k\\)). The fact that each task for each respondent has the same number of alternatives (3) helps. In addition, we need to convert the categorical variables for brand and ads into binary variables.\n\n# Step 1: Encode categorical variables\nconjoint_data['brand_N'] = (conjoint_data['brand'] == 'N').astype(int)\nconjoint_data['brand_P'] = (conjoint_data['brand'] == 'P').astype(int)\nconjoint_data['ad_Yes'] = (conjoint_data['ad'] == 'Yes').astype(int)\n\n# Step 2: Combine encoded categorical variables with numeric variables\nconjoint_data['price_scaled'] = conjoint_data['price']  # Keep price as numeric\nX = conjoint_data[['brand_N', 'brand_P', 'ad_Yes', 'price_scaled']].values\n\n# Step 3: Store structured data for estimation\ny = conjoint_data['choice'].values\nn, k = X.shape  # n = number of rows, k = number of covariates\n\n# Step 4: Check dimensions\nprint(f\"Number of observations (n): {n}\")\nprint(f\"Number of covariates (k): {k}\")\n\n# Step 5: Preview reshaped X as a DataFrame\nX_df = pd.DataFrame(X, columns=['brand_N', 'brand_P', 'ad_Yes', 'price_scaled'])\nprint(X_df.head())\n\nNumber of observations (n): 3000\nNumber of covariates (k): 4\n   brand_N  brand_P  ad_Yes  price_scaled\n0        0        1       0            32\n1        1        0       0            28\n2        1        0       0            24\n3        0        0       0            28\n4        0        0       0             8"
  },
  {
    "objectID": "projects/homework1/hw3_questions.html#interpreting-parameter-estimates-without-knowing-the-true-data-generating-process",
    "href": "projects/homework1/hw3_questions.html#interpreting-parameter-estimates-without-knowing-the-true-data-generating-process",
    "title": "Multinomial Logit Model",
    "section": "Interpreting Parameter Estimates Without Knowing the True Data-Generating Process",
    "text": "Interpreting Parameter Estimates Without Knowing the True Data-Generating Process\nIf we had not simulated the data and were instead analyzing results from a real-world conjoint survey, the parameter estimates shown would still provide valuable and intuitive insights about consumer preferences in the video streaming market. The estimates suggest that, holding other features constant, consumers derive the most utility from Netflix (β ≈ 0.59), followed by Amazon Prime (β ≈ 0.31), with Hulu implicitly serving as the baseline. The inequality 𝛽Netflix &gt; 𝛽Prime implies that consumers prefer Netflix to Prime, suggesting that Netflix enjoys higher brand equity or stronger perceived value. This is consistent with Netflix’s market position as a dominant streaming platform with a well-known content library.\nThe negative coefficients for the ad-supported format (β ≈ –0.43) and price (β ≈ –0.058) are also logical. The ad coefficient reflects a clear consumer preference for ad-free experiences, which aligns with the growing trend of users opting for premium subscriptions to avoid interruptions. Similarly, the negative price coefficient confirms price sensitivity: as subscription cost increases, the likelihood of a consumer choosing that option decreases. Taken together, these results are economically reasonable and would be credible inputs for managerial decisions around pricing strategy, product bundling, or feature prioritization—even without access to the underlying data-generating process. The tight confidence intervals further suggest that these insights are statistically robust and reliable.\ntodo: At a high level, discuss what change you would need to make in order to simulate data from — and estimate the parameters of — a multi-level (aka random-parameter or hierarchical) model. This is the model we use to analyze “real world” conjoint data."
  },
  {
    "objectID": "projects/homework1/hw4_questions.html",
    "href": "projects/homework1/hw4_questions.html",
    "title": "K-Means Analysis",
    "section": "",
    "text": "import pandas as pd\n\n# Load the datasets\n# Define file paths\npenguins_file_path = '/home/jovyan/Desktop/marketingwebsite/palmer_penguins.csv'\nyoghurt_file_path = '/home/jovyan/Desktop/marketingwebsite/yogurt_data.csv'\ndrivers_file_path = '/home/jovyan/Desktop/marketingwebsite/data_for_drivers_analysis.csv'\n\n# Load the datasets\npenguins_data = pd.read_csv(penguins_file_path)\nyoghurt_data = pd.read_csv(yoghurt_file_path)\ndrivers_data = pd.read_csv(drivers_file_path)\n\n# Display the first few rows of each dataset\nprint(\"Penguins Data:\")\nprint(penguins_data.head())\n\nprint(\"\\nYoghurt Data:\")\nprint(yoghurt_data.head())\n\nprint(\"\\nDrivers Data:\")\nprint(drivers_data.head())\n\nPenguins Data:\n  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n0  Adelie  Torgersen            39.1           18.7                181   \n1  Adelie  Torgersen            39.5           17.4                186   \n2  Adelie  Torgersen            40.3           18.0                195   \n3  Adelie  Torgersen            36.7           19.3                193   \n4  Adelie  Torgersen            39.3           20.6                190   \n\n   body_mass_g     sex  year  \n0         3750    male  2007  \n1         3800  female  2007  \n2         3250  female  2007  \n3         3450  female  2007  \n4         3650    male  2007  \n\nYoghurt Data:\n   id  y1  y2  y3  y4  f1  f2  f3  f4     p1     p2     p3     p4\n0   1   0   0   0   1   0   0   0   0  0.108  0.081  0.061  0.079\n1   2   0   1   0   0   0   0   0   0  0.108  0.098  0.064  0.075\n2   3   0   1   0   0   0   0   0   0  0.108  0.098  0.061  0.086\n3   4   0   1   0   0   0   0   0   0  0.108  0.098  0.061  0.086\n4   5   0   1   0   0   0   0   0   0  0.125  0.098  0.049  0.079\n\nDrivers Data:\n   brand   id  satisfaction  trust  build  differs  easy  appealing  \\\n0      1   98             3      1      0        1     1          1   \n1      1  179             5      0      0        0     0          0   \n2      1  197             3      1      0        0     1          1   \n3      1  317             1      0      0        0     0          1   \n4      1  356             4      1      1        1     1          1   \n\n   rewarding  popular  service  impact  \n0          0        0        1       0  \n1          0        0        0       0  \n2          1        0        1       1  \n3          0        1        1       1  \n4          1        1        1       1"
  },
  {
    "objectID": "projects/homework1/hw4_questions.html#a.-k-means",
    "href": "projects/homework1/hw4_questions.html#a.-k-means",
    "title": "K-Means Analysis",
    "section": "1a. K-Means",
    "text": "1a. K-Means\ntodo: write your own code to implement the k-means algorithm. Make plots of the various steps the algorithm takes so you can “see” the algorithm working. Test your algorithm on the Palmer Penguins dataset, specifically using the bill length and flipper length variables. Compare your results to the built-in kmeans function in R or Python.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\n# Extract relevant columns\ndata = penguins_data[['bill_length_mm', 'flipper_length_mm']].dropna().values\n\n# Initialize parameters\ndef kmeans_custom(data, k, max_iters=100, tol=1e-4):\n    np.random.seed(42)\n    centroids = data[np.random.choice(data.shape[0], k, replace=False)]\n    for iteration in range(max_iters):\n        # Assign clusters\n        distances = np.linalg.norm(data[:, np.newaxis] - centroids, axis=2)\n        labels = np.argmin(distances, axis=1)\n        \n        # Update centroids\n        new_centroids = np.array([data[labels == i].mean(axis=0) for i in range(k)])\n        \n        # Check for convergence\n        if np.linalg.norm(new_centroids - centroids) &lt; tol:\n            break\n        centroids = new_centroids\n    \n    return labels, centroids\n\n# Run custom K-Means\nk = 3\nlabels, centroids = kmeans_custom(data, k)\n\n# Plot results\nplt.scatter(data[:, 0], data[:, 1], c=labels, cmap='viridis', alpha=0.6, label='Data Points')\nplt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='x', s=100, label='Centroids')\nplt.xlabel('Bill Length (mm)')\nplt.ylabel('Flipper Length (mm)')\nplt.title('Custom K-Means Clustering')\nplt.legend()\nplt.show()\n\n# Compare with built-in KMeans\nkmeans = KMeans(n_clusters=k, random_state=42)\nkmeans_labels = kmeans.fit_predict(data)\nkmeans_centroids = kmeans.cluster_centers_\n\n# Plot built-in KMeans results\nplt.scatter(data[:, 0], data[:, 1], c=kmeans_labels, cmap='viridis', alpha=0.6, label='Data Points')\nplt.scatter(kmeans_centroids[:, 0], kmeans_centroids[:, 1], c='red', marker='x', s=100, label='Centroids')\nplt.xlabel('Bill Length (mm)')\nplt.ylabel('Flipper Length (mm)')\nplt.title('Built-in KMeans Clustering')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "projects/homework1/hw4_questions.html#b.-latent-class-mnl",
    "href": "projects/homework1/hw4_questions.html#b.-latent-class-mnl",
    "title": "K-Means Analysis",
    "section": "1b. Latent-Class MNL",
    "text": "1b. Latent-Class MNL\ntodo: Use the Yogurt dataset to estimate a latent-class MNL model. This model was formally introduced in the paper by Kamakura & Russell (1989); you may want to read or reference page 2 of the pdf, which is described in the class slides, session 4, slides 56-57.\nThe data provides anonymized consumer identifiers (id), a vector indicating the chosen product (y1:y4), a vector indicating if any products were “featured” in the store as a form of advertising (f1:f4), and the products’ prices in price-per-ounce (p1:p4). For example, consumer 1 purchased yogurt 4 at a price of 0.079/oz and none of the yogurts were featured/advertised at the time of consumer 1’s purchase. Consumers 2 through 7 each bought yogurt 2, etc. You may want to reshape the data from its current “wide” format into a “long” format.\ntodo: Fit the standard MNL model on these data. Then fit the latent-class MNL on these data separately for 2, 3, 4, and 5 latent classes.\ntodo: How many classes are suggested by the \\(BIC = -2*\\ell_n  + k*log(n)\\)? (where \\(\\ell_n\\) is the log-likelihood, \\(n\\) is the sample size, and \\(k\\) is the number of parameters.) The Bayesian-Schwarz Information Criterion link is a metric that assess the benefit of a better log likelihood at the expense of additional parameters to estimate – akin to the adjusted R-squared for the linear regression model. Note, that a lower BIC indicates a better model fit, accounting for the number of parameters in the model.\ntodo: compare the parameter estimates between (1) the aggregate MNL, and (2) the latent-class MNL with the number of classes suggested by the BIC."
  },
  {
    "objectID": "projects/homework1/hw4_questions.html#a.-k-nearest-neighbors",
    "href": "projects/homework1/hw4_questions.html#a.-k-nearest-neighbors",
    "title": "K-Means Analysis",
    "section": "2a. K Nearest Neighbors",
    "text": "2a. K Nearest Neighbors\ntodo: use the following code (or the python equivalent) to generate a synthetic dataset for the k-nearest neighbors algorithm. The code generates a dataset with two features, x1 and x2, and a binary outcome variable y that is determined by whether x2 is above or below a wiggly boundary defined by a sin function.\n\nimport numpy as np\nimport pandas as pd\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Generate data\nn = 100\nx1 = np.random.uniform(-3, 3, n)\nx2 = np.random.uniform(-3, 3, n)\nx = np.column_stack((x1, x2))\n\n# Define a wiggly boundary\nboundary = np.sin(4 * x1) + x1\ny = pd.Categorical((x2 &gt; boundary).astype(int))  # convert to categorical using pandas\n\n# Create DataFrame\ndat = pd.DataFrame({\n    'x1': x1,\n    'x2': x2,\n    'y': y\n})\n\n\n# Plot the synthetic dataset\nplt.figure(figsize=(8, 6))\nplt.scatter(dat['x1'], dat['x2'], c=dat['y'].cat.codes, cmap='coolwarm', alpha=0.7, edgecolor='k')\nplt.xlabel('x1')\nplt.ylabel('x2')\nplt.title('Synthetic Dataset with Wiggly Boundary')\n\n# Plot the wiggly boundary\nx1_boundary = np.linspace(-3, 3, 500)\nboundary = np.sin(4 * x1_boundary) + x1_boundary\nplt.plot(x1_boundary, boundary, color='black', linestyle='--', label='Boundary')\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\ntodo: plot the data where the horizontal axis is x1, the vertical axis is x2, and the points are colored by the value of y. You may optionally draw the wiggly boundary.\n\n# Plot the synthetic dataset\nplt.figure(figsize=(8, 6))\nplt.scatter(dat['x1'], dat['x2'], c=dat['y'].cat.codes, cmap='coolwarm', alpha=0.7, edgecolor='k')\nplt.xlabel('x1')\nplt.ylabel('x2')\nplt.title('Synthetic Dataset with Wiggly Boundary')\n\n# Plot the wiggly boundary\nx1_boundary = np.linspace(-3, 3, 500)\nboundary = np.sin(4 * x1_boundary) + x1_boundary\nplt.plot(x1_boundary, boundary, color='black', linestyle='--', label='Boundary')\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\ntodo: generate a test dataset with 100 points, using the same code as above but with a different seed.\n\n# Set a different random seed for the test dataset\nnp.random.seed(24)\n\n# Generate test data\nn_test = 100\nx1_test = np.random.uniform(-3, 3, n_test)\nx2_test = np.random.uniform(-3, 3, n_test)\nx_test = np.column_stack((x1_test, x2_test))\n\n# Define the wiggly boundary for the test dataset\nboundary_test = np.sin(4 * x1_test) + x1_test\ny_test = pd.Categorical((x2_test &gt; boundary_test).astype(int))  # convert to categorical using pandas\n\n# Create test DataFrame\ntest_dat = pd.DataFrame({\n    'x1': x1_test,\n    'x2': x2_test,\n    'y': y_test\n})\n\ntodo: implement KNN by hand. Check you work with a built-in function – eg, class::knn() or caret::train(method=\"knn\") in R, or scikit-learn’s KNeighborsClassifier in Python.\n\nfrom collections import Counter\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Implement KNN by hand\ndef knn_custom(train_data, train_labels, test_data, k):\n    predictions = []\n    for test_point in test_data:\n        # Calculate distances from the test point to all training points\n        distances = np.linalg.norm(train_data - test_point, axis=1)\n        # Find the k nearest neighbors\n        k_indices = np.argsort(distances)[:k]\n        k_nearest_labels = train_labels[k_indices]\n        # Determine the majority class\n        most_common = Counter(k_nearest_labels).most_common(1)[0][0]\n        predictions.append(most_common)\n    return np.array(predictions)\n\n# Prepare training and test data\ntrain_data = dat[['x1', 'x2']].values\ntrain_labels = dat['y'].cat.codes.values\ntest_data = test_dat[['x1', 'x2']].values\ntest_labels = test_dat['y'].cat.codes.values\n\n# Run custom KNN for k=5\nk = 5\ncustom_predictions = knn_custom(train_data, train_labels, test_data, k)\ncustom_accuracy = accuracy_score(test_labels, custom_predictions)\nprint(f\"Custom KNN Accuracy (k={k}): {custom_accuracy:.2f}\")\n\n# Check with built-in KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=k)\nknn.fit(train_data, train_labels)\nbuiltin_predictions = knn.predict(test_data)\nbuiltin_accuracy = accuracy_score(test_labels, builtin_predictions)\nprint(f\"Built-in KNN Accuracy (k={k}): {builtin_accuracy:.2f}\")\n\nCustom KNN Accuracy (k=5): 0.92\nBuilt-in KNN Accuracy (k=5): 0.92\n\n\ntodo: run your function for k=1,…,k=30, each time noting the percentage of correctly-classified points from the test dataset. Plot the results, where the horizontal axis is 1-30 and the vertical axis is the percentage of correctly-classified points. What is the optimal value of k as suggested by your plot?\n\n# Evaluate KNN for k=1 to k=30\nk_values = range(1, 31)\naccuracies = []\n\nfor k in k_values:\n    predictions = knn_custom(train_data, train_labels, test_data, k)\n    accuracy = accuracy_score(test_labels, predictions)\n    accuracies.append(accuracy)\n\n# Plot the results\nplt.figure(figsize=(10, 6))\nplt.plot(k_values, accuracies, marker='o', linestyle='-')\nplt.title('KNN Accuracy vs. Number of Neighbors (k)')\nplt.xlabel('Number of Neighbors (k)')\nplt.ylabel('Accuracy')\nplt.xticks(k_values)\nplt.grid()\nplt.show()\n\n# Find the optimal k\noptimal_k = k_values[np.argmax(accuracies)]\nprint(f\"Optimal k: {optimal_k} with accuracy: {max(accuracies):.2f}\")\n\n\n\n\n\n\n\n\nOptimal k: 1 with accuracy: 0.94"
  },
  {
    "objectID": "projects/homework1/hw4_questions.html#b.-key-drivers-analysis",
    "href": "projects/homework1/hw4_questions.html#b.-key-drivers-analysis",
    "title": "K-Means Analysis",
    "section": "2b. Key Drivers Analysis",
    "text": "2b. Key Drivers Analysis\ntodo: replicate the table on slide 75 of the session 5 slides. Specifically, using the dataset provided in the file data_for_drivers_analysis.csv, calculate: pearson correlations, standardized regression coefficients, “usefulness”, Shapley values for a linear regression, Johnson’s relative weights, and the mean decrease in the gini coefficient from a random forest. You may use packages built into R or Python; you do not need to perform these calculations “by hand.”\nIf you want a challenge, add additional measures to the table such as the importance scores from XGBoost, from a Neural Network, or from any additional method that measures the importance of variables."
  },
  {
    "objectID": "projects/homework1/hw4_questions.html#what-the-plots-show",
    "href": "projects/homework1/hw4_questions.html#what-the-plots-show",
    "title": "K-Means Analysis",
    "section": "What the Plots Show",
    "text": "What the Plots Show\n\nBoth scatter plots display:\nIndividual penguins as points, color-coded by their assigned cluster label.\nRed “X” markers indicating the final cluster centroids after convergence.\nThe top plot corresponds to the custom K-Means implementation.\nThe bottom plot corresponds to the built-in KMeans function from sklearn."
  },
  {
    "objectID": "projects/homework1/hw4_questions.html#interpretation-and-insights",
    "href": "projects/homework1/hw4_questions.html#interpretation-and-insights",
    "title": "K-Means Analysis",
    "section": "Interpretation and Insights:",
    "text": "Interpretation and Insights:\nCluster Structure: Both plots exhibit three distinct clusters, each grouping data points that share similar bill and flipper dimensions. This indicates that both implementations are capturing the same underlying structure in the data, aligning well with known biological groupings of penguin species.\nCentroid Positioning: The centroids in both implementations are almost identically placed, confirming that the custom algorithm is functioning correctly and converging toward the same solution as the built-in algorithm.\nThis also implies that the random initialization (with the same seed) and convergence logic used in both are effectively similar.\nCluster Separation: The clusters are well-separated, especially in the horizontal axis (bill length), showing that the features chosen are effective for unsupervised classification.\nThe middle cluster (likely corresponding to a species with intermediate bill and flipper lengths) is situated between the two more extreme clusters, illustrating a clear gradation in morphology.\nConsistency and Reliability: The near-identical results suggest that the custom K-Means algorithm is correctly implemented, making it a reliable educational or experimental tool when visualizing or modifying the clustering process manually."
  }
]