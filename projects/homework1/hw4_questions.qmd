---
title: "K-Means Analysis"
author: "Anjana Khabir"
date: June 12, 2025
---

```{python}
import pandas as pd

# Load the datasets
# Define file paths
penguins_file_path = '/home/jovyan/Desktop/marketingwebsite/palmer_penguins.csv'
yoghurt_file_path = '/home/jovyan/Desktop/marketingwebsite/yogurt_data.csv'
drivers_file_path = '/home/jovyan/Desktop/marketingwebsite/data_for_drivers_analysis.csv'

# Load the datasets
penguins_data = pd.read_csv(penguins_file_path)
yoghurt_data = pd.read_csv(yoghurt_file_path)
drivers_data = pd.read_csv(drivers_file_path)

# Display the first few rows of each dataset
print("Penguins Data:")
print(penguins_data.head())

print("\nYoghurt Data:")
print(yoghurt_data.head())

print("\nDrivers Data:")
print(drivers_data.head())
```

## 1a. K-Means

_todo: write your own code to implement the k-means algorithm.  Make plots of the various steps the algorithm takes so you can "see" the algorithm working.  Test your algorithm on the Palmer Penguins dataset, specifically using the bill length and flipper length variables.  Compare your results to the built-in `kmeans` function in R or Python._

```{python}
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# Extract relevant columns
data = penguins_data[['bill_length_mm', 'flipper_length_mm']].dropna().values

# Initialize parameters
def kmeans_custom(data, k, max_iters=100, tol=1e-4):
    np.random.seed(42)
    centroids = data[np.random.choice(data.shape[0], k, replace=False)]
    for iteration in range(max_iters):
        # Assign clusters
        distances = np.linalg.norm(data[:, np.newaxis] - centroids, axis=2)
        labels = np.argmin(distances, axis=1)
        
        # Update centroids
        new_centroids = np.array([data[labels == i].mean(axis=0) for i in range(k)])
        
        # Check for convergence
        if np.linalg.norm(new_centroids - centroids) < tol:
            break
        centroids = new_centroids
    
    return labels, centroids

# Run custom K-Means
k = 3
labels, centroids = kmeans_custom(data, k)

# Plot results
plt.scatter(data[:, 0], data[:, 1], c=labels, cmap='viridis', alpha=0.6, label='Data Points')
plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='x', s=100, label='Centroids')
plt.xlabel('Bill Length (mm)')
plt.ylabel('Flipper Length (mm)')
plt.title('Custom K-Means Clustering')
plt.legend()
plt.show()

# Compare with built-in KMeans
kmeans = KMeans(n_clusters=k, random_state=42)
kmeans_labels = kmeans.fit_predict(data)
kmeans_centroids = kmeans.cluster_centers_

# Plot built-in KMeans results
plt.scatter(data[:, 0], data[:, 1], c=kmeans_labels, cmap='viridis', alpha=0.6, label='Data Points')
plt.scatter(kmeans_centroids[:, 0], kmeans_centroids[:, 1], c='red', marker='x', s=100, label='Centroids')
plt.xlabel('Bill Length (mm)')
plt.ylabel('Flipper Length (mm)')
plt.title('Built-in KMeans Clustering')
plt.legend()
plt.show()

```
## What the Plots Show
- Both scatter plots display:
- Individual penguins as points, color-coded by their assigned cluster label.
- Red “X” markers indicating the final cluster centroids after convergence.
- The top plot corresponds to the custom K-Means implementation.
- The bottom plot corresponds to the built-in KMeans function from sklearn.

## Interpretation and Insights:

Cluster Structure: 
Both plots exhibit three distinct clusters, each grouping data points that share similar bill and flipper dimensions. This indicates that both implementations are capturing the same underlying structure in the data, aligning well with known biological groupings of penguin species.

Centroid Positioning:
The centroids in both implementations are almost identically placed, confirming that the custom algorithm is functioning correctly and converging toward the same solution as the built-in algorithm.

This also implies that the random initialization (with the same seed) and convergence logic used in both are effectively similar.

Cluster Separation:
The clusters are well-separated, especially in the horizontal axis (bill length), showing that the features chosen are effective for unsupervised classification.

The middle cluster (likely corresponding to a species with intermediate bill and flipper lengths) is situated between the two more extreme clusters, illustrating a clear gradation in morphology.

Consistency and Reliability:
The near-identical results suggest that the custom K-Means algorithm is correctly implemented, making it a reliable educational or experimental tool when visualizing or modifying the clustering process manually.

# Key Takeaways: 
- The visual similarity in cluster assignments and centroid locations demonstrates that the custom and built-in algorithms converge on a consistent and biologically meaningful clustering.
- These results validate the effectiveness of using bill length and flipper length for unsupervised segmentation of penguins.
- The plots reinforce that custom algorithms can replicate standard tools if implemented carefully, providing opportunities to further explore or animate the iterative learning process of K-Means.

_todo: Calculate both the within-cluster-sum-of-squares and silhouette scores (you can use built-in functions to do so) and plot the results for various numbers of clusters (ie, K=2,3,...,7). What is the "right" number of clusters as suggested by these two metrics?_

```{python}
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# Calculate WCSS and Silhouette Scores for K=2 to K=7
wcss = []
silhouette_scores = []
k_values = range(2, 8)

for k in k_values:
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(data)
    wcss.append(kmeans.inertia_)
    silhouette_scores.append(silhouette_score(data, labels))

# Plot WCSS and Silhouette Scores
plt.figure(figsize=(12, 5))

# Plot WCSS
plt.subplot(1, 2, 1)
plt.plot(k_values, wcss, marker='o')
plt.title('Within-Cluster Sum of Squares (WCSS)')
plt.xlabel('Number of Clusters (K)')
plt.ylabel('WCSS')

# Plot Silhouette Scores
plt.subplot(1, 2, 2)
plt.plot(k_values, silhouette_scores, marker='o')
plt.title('Silhouette Scores')
plt.xlabel('Number of Clusters (K)')
plt.ylabel('Silhouette Score')

plt.tight_layout()
plt.show()

# Print WCSS and Silhouette Scores for each K
for k, wcss_value, silhouette in zip(k_values, wcss, silhouette_scores):
    print(f"K={k}: WCSS={wcss_value:.2f}, Silhouette Score={silhouette:.2f}")
```

# Interpretations: 
The WCSS metric, which measures cluster compactness, consistently decreases with higher values of K because adding more clusters naturally tightens the grouping of data points. However, the key insight comes from identifying the "elbow" point — where the rate of improvement sharply slows. In your results, WCSS drops significantly from K=2 (≈ 20950) to K=3 (≈ 14270), and then the decrease becomes more gradual. This suggests that K=3 is the optimal point where adding another cluster begins to yield diminishing returns. In practice, this is interpreted as the elbow point, commonly used to determine a good balance between complexity and accuracy.

On the other hand, the Silhouette Score, which measures both cohesion and separation of clusters (ranging from -1 to 1), is highest at K=2 (0.61). A higher silhouette score means better-defined clusters. After K=2, the score drops (to 0.46 at K=3 and further thereafter), indicating that clusters begin to overlap more and are less well-separated. Therefore, purely from a separation perspective, K=2 is the strongest candidate.

# Summary:
K=2:
- Highest Silhouette Score (0.61)
- Best-defined, well-separated clusters

K=3:
- WCSS shows a clear elbow at this point
- Aligns with known biological structure (3 penguin species)

In conclusion, K=2 is mathematically optimal in terms of separation, but K=3 offers a practical and interpretable solution that reflects the likely biological groupings in the dataset. If interpretability and domain alignment are priorities, K=3 is recommended. If statistical purity is preferred, K=2 may be more appropriate.


## 1b. Latent-Class MNL

_todo: Use the Yogurt dataset to estimate a latent-class MNL model. This model was formally introduced in the paper by Kamakura & Russell (1989); you may want to read or reference page 2 of the pdf, which is described in the class slides, session 4, slides 56-57._



_The data provides anonymized consumer identifiers (`id`), a vector indicating the chosen product (`y1`:`y4`), a vector indicating if any products were "featured" in the store as a form of advertising (`f1`:`f4`), and the products' prices in price-per-ounce (`p1`:`p4`). For example, consumer 1 purchased yogurt 4 at a price of 0.079/oz and none of the yogurts were featured/advertised at the time of consumer 1's purchase.  Consumers 2 through 7 each bought yogurt 2, etc. You may want to reshape the data from its current "wide" format into a "long" format._

_todo: Fit the standard MNL model on these data.  Then fit the latent-class MNL on these data separately for 2, 3, 4, and 5 latent classes._

_todo: How many classes are suggested by the $BIC = -2*\ell_n  + k*log(n)$? (where $\ell_n$ is the log-likelihood, $n$ is the sample size, and $k$ is the number of parameters.) The Bayesian-Schwarz Information Criterion [link](https://en.wikipedia.org/wiki/Bayesian_information_criterion) is a metric that assess the benefit of a better log likelihood at the expense of additional parameters to estimate -- akin to the adjusted R-squared for the linear regression model. Note, that a **lower** BIC indicates a better model fit, accounting for the number of parameters in the model._

_todo: compare the parameter estimates between (1) the aggregate MNL, and (2) the latent-class MNL with the number of classes suggested by the BIC._



## 2a. K Nearest Neighbors

_todo: use the following code (or the python equivalent) to generate a synthetic dataset for the k-nearest neighbors algorithm.  The code generates a dataset with two features, `x1` and `x2`, and a binary outcome variable `y` that is determined by whether `x2` is above or below a wiggly boundary defined by a sin function._

```{python}
import numpy as np
import pandas as pd

# Set random seed for reproducibility
np.random.seed(42)

# Generate data
n = 100
x1 = np.random.uniform(-3, 3, n)
x2 = np.random.uniform(-3, 3, n)
x = np.column_stack((x1, x2))

# Define a wiggly boundary
boundary = np.sin(4 * x1) + x1
y = pd.Categorical((x2 > boundary).astype(int))  # convert to categorical using pandas

# Create DataFrame
dat = pd.DataFrame({
    'x1': x1,
    'x2': x2,
    'y': y
})
```

```{python}
# Plot the synthetic dataset
plt.figure(figsize=(8, 6))
plt.scatter(dat['x1'], dat['x2'], c=dat['y'].cat.codes, cmap='coolwarm', alpha=0.7, edgecolor='k')
plt.xlabel('x1')
plt.ylabel('x2')
plt.title('Synthetic Dataset with Wiggly Boundary')

# Plot the wiggly boundary
x1_boundary = np.linspace(-3, 3, 500)
boundary = np.sin(4 * x1_boundary) + x1_boundary
plt.plot(x1_boundary, boundary, color='black', linestyle='--', label='Boundary')

plt.legend()
plt.show()
```

_todo: plot the data where the horizontal axis is `x1`, the vertical axis is `x2`, and the points are colored by the value of `y`.  You may optionally draw the wiggly boundary._

```{python}
# Plot the synthetic dataset
plt.figure(figsize=(8, 6))
plt.scatter(dat['x1'], dat['x2'], c=dat['y'].cat.codes, cmap='coolwarm', alpha=0.7, edgecolor='k')
plt.xlabel('x1')
plt.ylabel('x2')
plt.title('Synthetic Dataset with Wiggly Boundary')

# Plot the wiggly boundary
x1_boundary = np.linspace(-3, 3, 500)
boundary = np.sin(4 * x1_boundary) + x1_boundary
plt.plot(x1_boundary, boundary, color='black', linestyle='--', label='Boundary')

plt.legend()
plt.show()
```

_todo: generate a test dataset with 100 points, using the same code as above but with a different seed._

```{python}
# Set a different random seed for the test dataset
np.random.seed(24)

# Generate test data
n_test = 100
x1_test = np.random.uniform(-3, 3, n_test)
x2_test = np.random.uniform(-3, 3, n_test)
x_test = np.column_stack((x1_test, x2_test))

# Define the wiggly boundary for the test dataset
boundary_test = np.sin(4 * x1_test) + x1_test
y_test = pd.Categorical((x2_test > boundary_test).astype(int))  # convert to categorical using pandas

# Create test DataFrame
test_dat = pd.DataFrame({
    'x1': x1_test,
    'x2': x2_test,
    'y': y_test
})
```

_todo: implement KNN by hand.  Check you work with a built-in function -- eg, `class::knn()` or `caret::train(method="knn")` in R, or scikit-learn's `KNeighborsClassifier` in Python._

```{python}
from collections import Counter
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Implement KNN by hand
def knn_custom(train_data, train_labels, test_data, k):
    predictions = []
    for test_point in test_data:
        # Calculate distances from the test point to all training points
        distances = np.linalg.norm(train_data - test_point, axis=1)
        # Find the k nearest neighbors
        k_indices = np.argsort(distances)[:k]
        k_nearest_labels = train_labels[k_indices]
        # Determine the majority class
        most_common = Counter(k_nearest_labels).most_common(1)[0][0]
        predictions.append(most_common)
    return np.array(predictions)

# Prepare training and test data
train_data = dat[['x1', 'x2']].values
train_labels = dat['y'].cat.codes.values
test_data = test_dat[['x1', 'x2']].values
test_labels = test_dat['y'].cat.codes.values

# Run custom KNN for k=5
k = 5
custom_predictions = knn_custom(train_data, train_labels, test_data, k)
custom_accuracy = accuracy_score(test_labels, custom_predictions)
print(f"Custom KNN Accuracy (k={k}): {custom_accuracy:.2f}")

# Check with built-in KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=k)
knn.fit(train_data, train_labels)
builtin_predictions = knn.predict(test_data)
builtin_accuracy = accuracy_score(test_labels, builtin_predictions)
print(f"Built-in KNN Accuracy (k={k}): {builtin_accuracy:.2f}")

```


_todo: run your function for k=1,...,k=30, each time noting the percentage of correctly-classified points from the test dataset. Plot the results, where the horizontal axis is 1-30 and the vertical axis is the percentage of correctly-classified points. What is the optimal value of k as suggested by your plot?_ 

```{python}
# Evaluate KNN for k=1 to k=30
k_values = range(1, 31)
accuracies = []

for k in k_values:
    predictions = knn_custom(train_data, train_labels, test_data, k)
    accuracy = accuracy_score(test_labels, predictions)
    accuracies.append(accuracy)

# Plot the results
plt.figure(figsize=(10, 6))
plt.plot(k_values, accuracies, marker='o', linestyle='-')
plt.title('KNN Accuracy vs. Number of Neighbors (k)')
plt.xlabel('Number of Neighbors (k)')
plt.ylabel('Accuracy')
plt.xticks(k_values)
plt.grid()
plt.show()

# Find the optimal k
optimal_k = k_values[np.argmax(accuracies)]
print(f"Optimal k: {optimal_k} with accuracy: {max(accuracies):.2f}")
```



## 2b. Key Drivers Analysis

_todo: replicate the table on slide 75 of the session 5 slides. Specifically, using the dataset provided in the file data_for_drivers_analysis.csv, calculate: pearson correlations, standardized regression coefficients, "usefulness", Shapley values for a linear regression, Johnson's relative weights, and the mean decrease in the gini coefficient from a random forest. You may use packages built into R or Python; you do not need to perform these calculations "by hand."_

_If you want a challenge, add additional measures to the table such as the importance scores from XGBoost, from a Neural Network, or from any additional method that measures the importance of variables._






