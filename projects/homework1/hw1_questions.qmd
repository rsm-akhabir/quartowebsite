---
title: "A Replication of Karlan and List (2007)"
author: "Your Name"
date: today
callout-appearance: minimal # this hides the blue "i" icon on .callout-notes
---


## Introduction

Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).

_to do: expand on the description of the experiment._

This project seeks to replicate their results.


## Data

### Description


_todo: Read the data into R/Python and describe the data_

Some observations from the summary statistics:
- The treatment variable has a mean of 0.666813, indicating about two-thirds of the sample received a treatment letter.

```{python}

import sys
print(sys.version)
```

```{python}
import pandas as pd

# Load the Stata file
file_path = "/home/jovyan/Desktop/marketingwebsite/karlan_list_2007.dta"
df = pd.read_stata(file_path)

# Display basic information
print("Dataset Info:")
print(df.info())

```

```{python}
# Show summary statistics
print("\nSummary statistics:")
print(df.describe(include='all'))
```

- The control variable has a mean of 0.333187, indicating one-third of the sample received the standard letter with no match.

- The ratio2 (2:1 match) and ratio3 (3:1 match) indicators each have a mean of approximately 0.222, meaning about 22% of the sample received these specific matching offers.

- The size25, size50, size100, and sizeno match threshold treatments each have means around 0.167, showing equal distribution across these four match threshold categories.


:::: {.callout-note collapse="true"}
### Variable Definitions

| Variable             | Description                                                         |
|----------------------|---------------------------------------------------------------------|
| `treatment`          | Treatment                                                           |
| `control`            | Control                                                             |
| `ratio`              | Match ratio                                                         |
| `ratio2`             | 2:1 match ratio                                                     |
| `ratio3`             | 3:1 match ratio                                                     |
| `size`               | Match threshold                                                     |
| `size25`             | \$25,000 match threshold                                            |
| `size50`             | \$50,000 match threshold                                            |
| `size100`            | \$100,000 match threshold                                           |
| `sizeno`             | Unstated match threshold                                            |
| `ask`                | Suggested donation amount                                           |
| `askd1`              | Suggested donation was highest previous contribution                |
| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |
| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |
| `ask1`               | Highest previous contribution (for suggestion)                      |
| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |
| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |
| `amount`             | Dollars given                                                       |
| `gave`               | Gave anything                                                       |
| `amountchange`       | Change in amount given                                              |
| `hpa`                | Highest previous contribution                                       |
| `ltmedmra`           | Small prior donor: last gift was less than median \$35              |
| `freq`               | Number of prior donations                                           |
| `years`              | Number of years since initial donation                              |
| `year5`              | At least 5 years since initial donation                             |
| `mrm2`               | Number of months since last donation                                |
| `dormant`            | Already donated in 2005                                             |
| `female`             | Female                                                              |
| `couple`             | Couple                                                              |
| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |
| `nonlit`             | Nonlitigation                                                       |
| `cases`              | Court cases from state in 2004-5 in which organization was involved |
| `statecnt`           | Percent of sample from state                                        |
| `stateresponse`      | Proportion of sample from the state who gave                        |
| `stateresponset`     | Proportion of treated sample from the state who gave                |
| `stateresponsec`     | Proportion of control sample from the state who gave                |
| `stateresponsetminc` | stateresponset - stateresponsec                                     |
| `perbush`            | State vote share for Bush                                           |
| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |
| `red0`               | Red state                                                           |
| `blue0`              | Blue state                                                          |
| `redcty`             | Red county                                                          |
| `bluecty`            | Blue county                                                         |
| `pwhite`             | Proportion white within zip code                                    |
| `pblack`             | Proportion black within zip code                                    |
| `page18_39`          | Proportion age 18-39 within zip code                                |
| `ave_hh_sz`          | Average household size within zip code                              |
| `median_hhincome`    | Median household income within zip code                             |
| `powner`             | Proportion house owner within zip code                              |
| `psch_atlstba`       | Proportion who finished college within zip code                     |
| `pop_propurban`      | Proportion of population urban within zip code                      |

::::


### Balance Test 

As an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.

_todo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)._


## Experimental Results

### Charitable Contribution Made

First, I analyze whether matched donations lead to an increased response rate of making a donation. 

_todo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control._

```{python}
import matplotlib.pyplot as plt

# Calculate the proportion of people who donated in each group
treatment_proportion = df[df['treatment'] == 1]['gave'].mean()
control_proportion = df[df['control'] == 1]['gave'].mean()

# Create the barplot
plt.bar(['Treatment', 'Control'], [treatment_proportion, control_proportion], color=['blue', 'orange'])
plt.ylabel('Proportion of People Who Donated')
plt.title('Proportion of Donors by Group')
# Display the proportions
print(f"Proportion of people who donated in the Treatment group: {treatment_proportion:.2%}")
print(f"Proportion of people who donated in the Control group: {control_proportion:.2%}")

plt.show()
```


_todo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)_

```{python}
from scipy.stats import ttest_ind

%pip install statsmodels
import statsmodels.formula.api as smf
import statsmodels.api as sm
```

```{python}
import statsmodels.api as sm

# Add an intercept column to the DataFrame
df['intercept'] = 1

# Perform a bivariate linear regression
bivariate_model = sm.OLS(df['gave'], df[['intercept', 'treatment']])
bivariate_results = bivariate_model.fit()

print("\nBivariate Linear Regression results:")
print(bivariate_results.summary())

# Extract the p-value for the treatment variable
bivariate_p_value = bivariate_results.pvalues['treatment']
print(f"\nP-value for treatment in bivariate regression: {bivariate_p_value:.4f}")

```

```{python}
# Perform a probit regression
probit_model = smf.probit('gave ~ treatment', data=df)
probit_results = probit_model.fit()

# Display the summary of the probit regression
print("\nProbit Regression results:")
print(probit_results.summary())
```

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

P-value for treatment in bivariate regression: 0.0019
_todo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper._


### Differences between Match Rates

Next, I assess the effectiveness of different sizes of matched donations on the response rate.

_todo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the "figures suggest" comment the authors make on page 8?_

```{python}

# Extract unique match ratios
match_ratios = df['ratio'].unique()

# Perform pairwise t-tests between match ratios
for i in range(len(match_ratios)):
    for j in range(i + 1, len(match_ratios)):
        ratio1 = match_ratios[i]
        ratio2 = match_ratios[j]
        
        # Filter data for the two match ratios
        group1 = df[df['ratio'] == ratio1]['gave'].dropna()
        group2 = df[df['ratio'] == ratio2]['gave'].dropna()
        
        # Perform t-test
        t_stat, p_value = ttest_ind(group1, group2, equal_var=False)
        
        # Print results
        print(f"T-test between match ratios {ratio1} and {ratio2}:")
        print(f"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\n")

```

_todo: Assess the same issue using a regression. Specifically, create the variable `ratio1` then regress `gave` on `ratio1`, `ratio2`, and `ratio3` (or alternatively, regress `gave` on the categorical variable `ratio`). Interpret the coefficients and their statistical precision._

```{python}

# Create the variable `ratio1` from the `ratio` column
df['ratio1'] = (df['ratio'] == 1).astype(int)

# Perform the regression
regression_model = sm.OLS(df['gave'], df[['intercept', 'ratio1', 'ratio2', 'ratio3']])
regression_results = regression_model.fit()

# Display the regression results
print("\nRegression results:")
print(regression_results.summary())

```


_todo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios.  Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?_

```{python}

# Directly from the data
response_rate_1_1 = df[df['ratio'] == 1]['gave'].mean()
response_rate_2_1 = df[df['ratio'] == 2]['gave'].mean()
response_rate_3_1 = df[df['ratio'] == 3]['gave'].mean()

difference_1_1_2_1 = response_rate_1_1 - response_rate_2_1
difference_2_1_3_1 = response_rate_2_1 - response_rate_3_1

print(f"Response rate difference (1:1 - 2:1): {difference_1_1_2_1:.4f}")
print(f"Response rate difference (2:1 - 3:1): {difference_2_1_3_1:.4f}")

# Using fitted coefficients from the regression
coefficients = regression_results.params
difference_1_1_2_1_coeff = coefficients[1]  # Coefficient for ratio 2
difference_2_1_3_1_coeff = coefficients[2] - coefficients[1]  # Difference between coefficients for ratio 3 and ratio 2

print(f"Response rate difference from coefficients (1:1 - 2:1): {difference_1_1_2_1_coeff:.4f}")
print(f"Response rate difference from coefficients (2:1 - 3:1): {difference_2_1_3_1_coeff:.4f}")

```

Increasing donation match ratios from 1:1 to 2:1 slightly boosts response rates, but moving from 2:1 to 3:1 offers minimal additional impact. Response rates rise from 2.07% (1:1) to 2.26% (2:1) and only slightly to 2.27% (3:1), with diminishing returns evident in both response differences and regression coefficients. This suggests that while a moderate increase in match size can be effective, higher ratios beyond 2:1 may not significantly enhance donor motivation.

### Size of Charitable Contribution

In this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.

_todo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?_

```{python}
# Perform a bivariate linear regression of donation amount on treatment status
bivariate_amount_model = sm.OLS(df['amount'], df[['intercept', 'treatment']])
bivariate_amount_results = bivariate_amount_model.fit()

# Display the regression results
print("\nBivariate Linear Regression results for donation amount on treatment status:")
print(bivariate_amount_results.summary())
```

Observations:

Effect of Treatment on Donation Amount:
The coefficient for the treatment variable is 0.1536, indicating that being in the treatment group (e.g., exposed to a donation match offer) is associated with an increase of approximately $0.15 in the average donation amount. However, this effect is not statistically significant at the conventional 5% level (p = 0.063), suggesting we cannot confidently conclude that treatment has a real impact on donation amount.

Model Fit:
The R-squared value is 0.000, indicating that the model explains virtually none of the variation in donation amount. This is common in social science data but implies that other factors (beyond just treatment status) are likely influencing donation amounts.

Statistical Significance:
While the p-value for the treatment variable (0.063) is close to 0.05, it slightly exceeds it, meaning the result is only marginally significant. This suggests a possible, but weak, effect of treatment on donation amount that might warrant further investigation with a larger sample or additional controls.

Baseline Donation Amount:
The intercept is 0.8133, indicating that individuals in the control group donated around $0.81 on average.

_todo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients -- what did we learn? Does the treatment coefficient have a causal interpretation?_ 

```{python}

# Filter the data to include only people who made a donation
donors_df = df[df['gave'] == 1]

# Perform a bivariate linear regression of donation amount on treatment status for donors
bivariate_donors_model = sm.OLS(donors_df['amount'], donors_df[['intercept', 'treatment']])
bivariate_donors_results = bivariate_donors_model.fit()

# Display the regression results
print("\nBivariate Linear Regression results for donation amount on treatment status (donors only):")
print(bivariate_donors_results.summary())

```

INTERPRETATIONS:
- Donors in the treatment group gave about $1.67 less on average than those in the control group. However, this difference is not statistically significant (p-value = 0.561), meaning we can’t confidently say it’s a real effect.

- There’s no strong evidence that treatment affects the amount donated, conditional on donating.

- The treatment coefficient should not be interpreted causally because the sample is restricted to donors only.

- Treatment could influence both whether someone donates and how much they give. By only analyzing donors, we’re conditioning on a post-treatment outcome, which can lead to biased estimates (known as collider bias).


_todo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot._

```{python}

import matplotlib.pyplot as plt

# Filter donation amounts for treatment and control groups among donors
treatment_donations = donors_df[donors_df['treatment'] == 1]['amount']
control_donations = donors_df[donors_df['control'] == 1]['amount']

# Calculate the sample averages
treatment_avg = treatment_donations.mean()
control_avg = control_donations.mean()

# Create the histograms
fig, axes = plt.subplots(1, 2, figsize=(12, 6), sharey=True)

# Treatment group histogram
axes[0].hist(treatment_donations, bins=30, color='blue', alpha=0.7, edgecolor='black')
axes[0].axvline(treatment_avg, color='red', linestyle='--', label=f'Avg: {treatment_avg:.2f}')
axes[0].set_title('Treatment Group')
axes[0].set_xlabel('Donation Amount')
axes[0].set_ylabel('Frequency')
axes[0].legend()

# Control group histogram
axes[1].hist(control_donations, bins=30, color='green', alpha=0.7, edgecolor='black')
axes[1].axvline(control_avg, color='red', linestyle='--', label=f'Avg: {control_avg:.2f}')
axes[1].set_title('Control Group')
axes[1].set_xlabel('Donation Amount')
axes[1].legend()

# Display the plots
plt.tight_layout()
plt.show()

```

## Simulation Experiment

As a reminder of how the t-statistic "works," in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.

Suppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. 

Further suppose that the true distribution of respondents who do get a charitable donation match of any size  is Bernoulli with probability p=0.022 that a donation is made.

```{python}

import numpy as np

import matplotlib.pyplot as plt

# Parameters
p_no_match = 0.018  # Probability of donation without match
p_with_match = 0.022  # Probability of donation with match
sample_sizes = [10, 50, 100, 500, 1000, 5000, 10000]  # Different sample sizes
num_simulations = 1000  # Number of simulations for CLT

# Law of Large Numbers (LLN)
means_no_match = []
means_with_match = []

for size in sample_sizes:
    sample_no_match = np.random.binomial(1, p_no_match, size)
    sample_with_match = np.random.binomial(1, p_with_match, size)
    means_no_match.append(np.mean(sample_no_match))
    means_with_match.append(np.mean(sample_with_match))

# Plot LLN
plt.figure(figsize=(12, 6))
plt.plot(sample_sizes, means_no_match, label="No Match (p=0.018)", marker='o')
plt.plot(sample_sizes, means_with_match, label="With Match (p=0.022)", marker='o')
plt.axhline(y=p_no_match, color='blue', linestyle='--', label="True Mean (No Match)")
plt.axhline(y=p_with_match, color='orange', linestyle='--', label="True Mean (With Match)")
plt.xlabel("Sample Size")
plt.ylabel("Sample Mean")
plt.title("Law of Large Numbers")
plt.legend()
plt.grid()
plt.show()

# Central Limit Theorem (CLT)
sample_means_no_match = []
sample_means_with_match = []

for _ in range(num_simulations):
    sample_no_match = np.random.binomial(1, p_no_match, 1000)  # Fixed sample size
    sample_with_match = np.random.binomial(1, p_with_match, 1000)
    sample_means_no_match.append(np.mean(sample_no_match))
    sample_means_with_match.append(np.mean(sample_with_match))

# Plot CLT
plt.figure(figsize=(12, 6))
plt.hist(sample_means_no_match, bins=30, alpha=0.7, label="No Match (p=0.018)", color='blue', edgecolor='black')
plt.hist(sample_means_with_match, bins=30, alpha=0.7, label="With Match (p=0.022)", color='orange', edgecolor='black')
plt.axvline(x=p_no_match, color='blue', linestyle='--', label="True Mean (No Match)")
plt.axvline(x=p_with_match, color='orange', linestyle='--', label="True Mean (With Match)")
plt.xlabel("Sample Mean")
plt.ylabel("Frequency")
plt.title("Central Limit Theorem")
plt.legend()
plt.grid()
plt.show()

```

### Law of Large Numbers

_to do:  Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 10,000 draws from the control distribution and 10,000 draws from the treatment distribution. You'll then calculate a vector of 10,000 differences, and then you'll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means._

```{python}
import numpy as np

# Filter the control group
control_amounts = df[df['control'] == 1]['amount']

# Simulate 100,000 draws from the control distribution
simulated_draws = np.random.choice(control_amounts, size=100000, replace=True)

# Display summary statistics of the simulated draws
print(f"Simulated Draws Summary:")
print(f"Mean: {np.mean(simulated_draws):.4f}")
print(f"Standard Deviation: {np.std(simulated_draws):.4f}")
print(f"Min: {np.min(simulated_draws):.4f}")
print(f"Max: {np.max(simulated_draws):.4f}")
```

```{python}
# Filter the treatment group
treatment_amounts = df[df['treatment'] == 1]['amount']

# Simulate 10,000 draws from the treatment distribution
simulated_treatment_draws = np.random.choice(treatment_amounts, size=10000, replace=True)

# Display summary statistics of the simulated treatment draws
print(f"Simulated Treatment Draws Summary:")
print(f"Mean: {np.mean(simulated_treatment_draws):.4f}")
print(f"Standard Deviation: {np.std(simulated_treatment_draws):.4f}")
print(f"Min: {np.min(simulated_treatment_draws):.4f}")
print(f"Max: {np.max(simulated_treatment_draws):.4f}")
```


```{python}
# Simulate 100,000 draws from the control distribution
simulated_control_draws = np.random.choice(control_amounts, size=100000, replace=True)

# Simulate 10,000 draws from the treatment distribution
simulated_treatment_draws = np.random.choice(treatment_amounts, size=10000, replace=True)

# Calculate a vector of 10,000 differences
differences = simulated_treatment_draws - simulated_control_draws[:10000]

# Calculate the cumulative average of the differences
cumulative_avg = np.cumsum(differences) / np.arange(1, len(differences) + 1)

# Plot the cumulative average
plt.figure(figsize=(10, 6))
plt.plot(cumulative_avg, label="Cumulative Average of Differences")
plt.axhline(0, color='red', linestyle='--', label="Zero Line")
plt.xlabel("Number of Differences")
plt.ylabel("Cumulative Average")
plt.title("Cumulative Average of Differences Between Treatment and Control")
plt.legend()
plt.grid()
plt.show()

```

```{python}
from scipy.stats import norm

# Add a distribution curve to the plot
# Fit a normal distribution to the differences
mean_diff = np.mean(differences)
std_diff = np.std(differences)

# Generate x values for the curve
x = np.linspace(min(differences), max(differences), 1000)
y = norm.pdf(x, mean_diff, std_diff)

# Plot the distribution curve
plt.figure(figsize=(10, 6))
plt.plot(x, y, label="Normal Distribution Curve", color='purple')
plt.hist(differences, bins=50, density=True, alpha=0.6, color='gray', edgecolor='black')
plt.axvline(0, color='red', linestyle='--', label="Zero Line")
plt.xlabel("Differences")
plt.ylabel("Density")
plt.title("Distribution of Differences with Fitted Curve")
plt.legend()
plt.grid()
plt.show()
```
### Central Limit Theorem

_to do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the "middle" of the distribution or whether it's in the "tail."_





